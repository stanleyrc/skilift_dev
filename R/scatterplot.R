internal_settings_path = system.file("extdata", "test_data", "settings.json", package = "Skilift")

#' Converts a color from hexadecimal to numeric format
#'
#' @param color A character vector of colors in hexadecimal format (e.g., "#FF0000").
#' @return A numeric vector representing the colors.
color2numeric <- function(color) {
    # Remove the '#' character if present
    color <- gsub("#", "", color)
    # Convert hexadecimal to numeric
    return(as.numeric(strtoi(color, base = 16L)))
}


#'
#' @param ref_seqinfo_json Path to the JSON file containing metadata.
#' @param ref Optional reference name. If not provided, the default reference is used.
#' @return A data.table containing the sequence information for the specified reference.
get_ref_metadata <- function(ref_seqinfo_json, ref = NULL) {
    meta <- jsonlite::read_json(ref_seqinfo_json)
    
    if (!("coordinates" %in% names(meta))) {
        stop("Input meta file is not a proper settings.json format.")
    }
    
    coord <- meta$coordinates
    
    if (is.null(ref)) {
        if (!("default" %in% names(coord))) {
            stop(ref_seqinfo_json, " is missing a default coordinates attribute")
        }
        ref <- coord$default
        message('No reference name provided so using default: "', ref, '".')
    }
    
    if (!("sets" %in% names(coord))) {
        stop("Could not find reference sets in ", ref_seqinfo_json, "in attribute 'sets'.")
    }
    
    sets <- coord$sets
    
    if (!(ref %in% names(sets))) {
        stop(ref, " does not appear in set of references in ", ref_seqinfo_json)
    }
    
    seq.info <- data.table::rbindlist(sets[[ref]])
    return(seq.info)
}

#' @name granges_to_arrow_scatterplot
#' @description
#'
#' Converts GRanges into an arrow file
#'
#' @param gr_path input GRanges
#' @param field name of GRanges column to use as arrow Y axis
#' @param ref the name of the reference to use.
#' 
#' @importFrom arrow Table write_feather schema float32
#' @importFrom gGnome cov2cov.js
#' @param cov.color.field name of GRanges column containing color of each point
#' @param overwrite (logical) by default, if the output path already exists, it will not be overwritten.
#' @param ref_seqinfo_json path to JSON file with ref seqlengths
#' @param bin.width (integer) bin width for rebinning the coverage (default: 1e4)
#' @return arrow table
#' @author Alon Shaiber, Shihab Dider
granges_to_arrow_scatterplot = function(
    gr_path,
    field = "foreground",
    ref = 'hg19',
    cov.color.field = NULL,
    ref_seqinfo_json = internal_settings_path,
    bin.width = 1e4,
    ...){

    if (!requireNamespace("arrow", quietly = TRUE)) {
        stop('You must have the package "arrow" installed in order for this function to work. Please install it.')
    }

    message('Preparing GRanges for conversion to arrow format')
    dat = gGnome::cov2cov.js(
        gr_path,
        meta.js = ref_seqinfo_json,
        js.type = 'PGV',
        field = field,
        ref = ref,
        cov.color.field = cov.color.field,
        ...
    )

    if (!is.null(cov.color.field)){
        dat[, color := color2numeric(get(cov.color.field))]
    } else {
        if (!is.null(ref_seqinfo_json)){
            ref_meta = get_ref_metadata(ref_seqinfo_json, ref)
            data.table::setkey(ref_meta, 'chromosome')
            dat$color = color2numeric(ref_meta[dat$seqnames]$color)
        } else {
            dat$color = 0
        }
    }

    outdt = dat[, .(x = new.start, y = get(field), color)]

    # if there are any NAs for colors then set those to black
    outdt[is.na(color), color := 0]

    # remove NAs
    outdt = outdt[!is.na(y)]

    # sort according to x values (that is what front-end expects)
    outdt = outdt[order(x)]

    arrow_table = arrow::Table$create(
        outdt,
        schema = arrow::schema(
            x = arrow::float32(),
            y = arrow::float32(),
            color = arrow::float32()
        )
    )
    return(arrow_table)
}

#' @name make_allelic_hets
#' @title make_allelic_hets
#'
#' @description
#'
#' returns melted hetsnps gRanges with allelic (major/minor) counts
#'
#' @param het_pileups (character) path to sites.txt with hetsnps
#' @param min_normal_freq (numeric) in [0, 1] min frequency in normal to count as het site
#' @param max_normal_freq (numeric) in [0, 1] max frequency in normal to count as het site
#'
#' @return GRanges with major and minor counts
#' @author Jonathan Rafailov, Shihab Dider
make_allelic_hetsnps <- function(
    het_pileups = NULL,
    min_normal_freq = 0.2,
    max_normal_freq = 0.8
) {
    if (is.null(het_pileups) || !file.exists(het_pileups)) {
        stop("Please provide a valid path to a hetsnps file.")
    }

    ## prepare and filter
    hetsnps_dt <- fread(het_pileups)[alt.frac.n > min_normal_freq & alt.frac.n < max_normal_freq, ]
    ## add major and minor
    hetsnps_dt[, which.major := ifelse(alt.count.t > ref.count.t, "alt", "ref")]
    hetsnps_dt[, major.count := ifelse(which.major == "alt", alt.count.t, ref.count.t)]
    hetsnps_dt[, minor.count := ifelse(which.major == "alt", ref.count.t, alt.count.t)]

    ## melt the data frame
    hetsnps_melted <- rbind(
        hetsnps_dt[, .(seqnames, start, end, count = major.count, allele = "major")],
        hetsnps_dt[, .(seqnames, start, end, count = minor.count, allele = "minor")]
    )

    ## make GRanges
    allelic_hetsnps <- dt2gr(hetsnps_melted[, .(seqnames, start, end, count, allele)])

    return(allelic_hetsnps)
}


#' @name subsample_hetsnps
#' @title subsample_hetsnps
#' @description subsets the hetsnps to masked unique sites and colors by major/minor allele
#'
#' @param het_pileups sites.txt from het pileups
#' @param mask rds file with masked regions
#' @param sample_size number of snps to randomly sample
#' @export
#' @author Jonathan Rafailov, Shihab Dider
subsample_hetsnps <- function(
    het_pileups,
    mask = NULL,
    sample_size = 100000,
    seed = 42
    ) {
    if (is.null(het_pileups)) {
        stop("Please provide a valid path to a hetsnps file.")
    }

    if (is.null(mask)) {
        warning("No mask provided, using default mask.")
        maska_path <- system.file("extdata", "data", "maskA_re.rds", package = "Skilift")
        maska <- readRDS(maska_path)
    } else {
        maska <- readRDS(mask)
    }

    # apply mask 
    allelic_hetsnps <- make_allelic_hetsnps(het_pileups)
    allelic_hetsnps <- gr.val(allelic_hetsnps, maska, "mask")
    allelic_hetsnps <- allelic_hetsnps %Q% (is.na(mask))
    allelic_hetsnps$mask <- NULL

    # color by allele
    allelic_hetsnps$col <- ifelse(allelic_hetsnps$allele == "major", "red", "blue")

    # subset to unique sites
    unique_snps <- unique(gr2dt(allelic_hetsnps)[, .(seqnames, start, end)])
    n_snps <- nrow(unique_snps)
    message(paste(n_snps, "snps found"))

    # subsample to reduce number of points drawn on front-end scatterplot
    if (!is.na(sample_size) && n_snps > sample_size) {
        message(paste("subsampling", sample_size, "points..."))
        set.seed(seed) ## should set seed for reproducibility
        snps_to_include <- unique_snps[sample(n_snps, sample_size)] %>% dt2gr()
        subsampled_allelic_hetsnps <- allelic_hetsnps %&% snps_to_include
    } else {
        snps_to_include <- unique_snps %>% dt2gr()
        subsampled_allelic_hetsnps <- allelic_hetsnps %&% snps_to_include
    }

    return(subsampled_allelic_hetsnps)
}

#' @name lift_denoised_coverage
#' @title lift_denoised_coverage
#' @description
#' Create denoised coverage arrow files for all samples in a cohort
#'
#' @param cohort Cohort object containing sample information
#' @param output_data_dir Base directory for output files
#' @param cores Number of cores for parallel processing (default: 1)
#' @return None
#' @export
lift_denoised_coverage <- function(cohort, output_data_dir, cores = 1) {
    if (!inherits(cohort, "Cohort")) {
        stop("Input must be a Cohort object")
    }
    
    if (!dir.exists(output_data_dir)) {
        dir.create(output_data_dir, recursive = TRUE)
    }
    
    # Validate required columns exist
    required_cols <- c("pair", "tumor_coverage")
    missing_cols <- required_cols[!required_cols %in% names(cohort$inputs)]
    if (length(missing_cols) > 0) {
        stop("Missing required columns in cohort: ", paste(missing_cols, collapse = ", "))
    }
    
    # Process each sample in parallel
    mclapply(seq_len(nrow(cohort$inputs)), function(i) {
        row <- cohort$inputs[i,]
        pair_dir <- file.path(output_data_dir, row$pair)
        
        if (!dir.exists(pair_dir)) {
            dir.create(pair_dir, recursive = TRUE)
        }
        
        out_file <- file.path(pair_dir, "coverage.arrow")
        
        tryCatch({
            if (!is.null(row$tumor_coverage) && file.exists(row$tumor_coverage)) {
                # Create arrow table
                arrow_table <- granges_to_arrow_scatterplot(
                    gr_path = row$tumor_coverage,
                    field = "foreground",
                    ref = cohort$reference_name,
                )
                
                # Write arrow table
                message(sprintf("Writing coverage arrow file for %s", row$pair))
                arrow::write_feather(arrow_table, out_file, compression = "uncompressed")
            } else {
                warning(sprintf("Tumor coverage file missing for %s", row$pair))
            }
        }, error = function(e) {
            warning(sprintf("Error processing %s: %s", row$pair, e$message))
        })
    }, mc.cores = cores)
    
    invisible(NULL)
}

#' @name lift_hetsnps
#' @title lift_hetsnps
#' @description
#' Create hetsnps arrow files for all samples in a cohort
#'
#' @param cohort Cohort object containing sample information
#' @param output_data_dir Base directory for output files
#' @param cores Number of cores for parallel processing (default: 1)
#' @return None
#' @export
lift_hetsnps <- function(cohort, output_data_dir, cores = 1) {
    if (!inherits(cohort, "Cohort")) {
        stop("Input must be a Cohort object")
    }
    
    if (!dir.exists(output_data_dir)) {
        dir.create(output_data_dir, recursive = TRUE)
    }
    
    # Validate required columns exist
    required_cols <- c("pair", "het_pileups")
    missing_cols <- required_cols[!required_cols %in% names(cohort$inputs)]
    if (length(missing_cols) > 0) {
        stop("Missing required columns in cohort: ", paste(missing_cols, collapse = ", "))
    }
    
    # Process each sample in parallel
    mclapply(seq_len(nrow(cohort$inputs)), function(i) {
        row <- cohort$inputs[i,]
        pair_dir <- file.path(output_data_dir, row$pair)
        
        if (!dir.exists(pair_dir)) {
            dir.create(pair_dir, recursive = TRUE)
        }
        
        out_file <- file.path(pair_dir, "hetsnps.arrow")
        
        tryCatch({
            if (!is.null(row$het_pileups) && file.exists(row$het_pileups)) {
                # Subsample hetsnps
                hetsnps_gr <- subsample_hetsnps(
                    het_pileups = row$het_pileups
                )

                # col2numeric() in granges_to_arrow_scatterplot
                # expects a hexadecimal color value, not a name
                hetsnps_gr$col = grDevices::rgb(
                    t(
                        grDevices::col2rgb(hetsnps_gr$col)
                    ), 
                    maxColorValue = 255
                )
                
                # Create arrow table
                arrow_table <- granges_to_arrow_scatterplot(
                    gr_path = hetsnps_gr,
                    field = "count",
                    ref = cohort$reference_name,
                    cov.color.field = "col"
                )
                
                # Write arrow table
                message(sprintf("Writing hetsnps arrow file for %s", row$pair))
                arrow::write_feather(arrow_table, out_file, compression = "uncompressed")
            } else {
                warning(sprintf("Het pileups file missing for %s", row$pair))
            }
        }, error = function(e) {
            warning(sprintf("Error processing %s: %s", row$pair, e$message))
        })
    }, mc.cores = cores)
    
    invisible(NULL)
}



#' @name lift_coverage_track
#' @title lift_coverage_track
#' @description
#' Create coverage arrow files for all samples in a cohort.
#' Inputs can be any GRanges with a color field
#'
#' @param cohort Cohort object containing sample information
#' @param output_data_dir Base directory for output files
#' @param cores Number of cores for parallel processing (default: 1)
#' @param cohort_column Field in cohort inputs table that specifies the source data
#' @param coverage_field Field in the input GRanges object that specifies the values to write to arrow
#' @param color_field Field in the input GRanges object that specifies the color values. Note this must be a hexadecimal value.
#' @return None
#' @export
lift_coverage_track <- function(
    cohort, 
    output_data_dir, 
    cores = 1, 
    cohort_column = "tumor_coverage", 
    coverage_field = "foreground", 
    color_field = NULL
    ) {
    if (!inherits(cohort, "Cohort")) {
        stop("Input must be a Cohort object")
    }
    
    if (!dir.exists(output_data_dir)) {
        dir.create(output_data_dir, recursive = TRUE)
    }

    if (
        missing(coverage_field) && 
        identical(coverage_field, "foreground")
    ) {
        warning("default coverage_field 'foreground' will be used to create arrow plot")
    }

    if (
        missing(cohort_column) && 
        identical(cohort_column, "tumor_coverage")
    ) {
        warning("default cohort_column 'tumor_coverage' will be used to create arrow plot")
    }
    
    # Validate required columns exist
    required_cols <- c("pair", cohort_column)
    missing_cols <- required_cols[!required_cols %in% names(cohort$inputs)]
    if (length(missing_cols) > 0) {
        stop("Missing required columns in cohort: ", paste(missing_cols, collapse = ", "))
    }

    
    # Process each sample in parallel
    mclapply(seq_len(nrow(cohort$inputs)), function(i) {
        row <- cohort$inputs[i,]
        pair_dir <- file.path(output_data_dir, row$pair)
        
        if (!dir.exists(pair_dir)) {
            dir.create(pair_dir, recursive = TRUE)
        }
        
        out_file <- file.path(pair_dir, "coverage.arrow")
        
        tryCatch({
            if (!is.null(row[[cohort_column]]) && file.exists(row[[cohort_column]])) {
                # Create arrow table
                arrow_table <- granges_to_arrow_scatterplot(
                    gr_path = row[[cohort_column]],
                    field = coverage_field,
                    ref = cohort$reference_name,
                    cov.color.field = color_field
                )
                
                # Write arrow table
                message(sprintf("Writing coverage arrow file for %s", row$pair))
                arrow::write_feather(arrow_table, out_file, compression = "uncompressed")
            } else {
                warning(sprintf("%s file missing for %s", cohort_column, row$pair))
            }
        }, error = function(e) {
            warning(sprintf("Error processing %s: %s", row$pair, e$message))
        })
    }, mc.cores = cores)
    
    invisible(NULL)
}
