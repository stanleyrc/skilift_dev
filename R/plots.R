library(VariantAnnotation)
library(skitools)

#' @name cov2arrowPGV
#' @description
#'
#' Prepares an scatter plot arrow file with coverage info for PGV (https://github.com/mskilab/pgv)
#'
#' @param cov input coverage data (GRanges)
#' @param field which field of the input data to use for the Y axis
#' @param output_file output file path.
#' @param ref the name of the reference to use. If not provided, then the default reference that is defined in the meta.js file will be loaded.
#' @param cov.color.field a field in the input GRanges object to use to determine the color of each point
#' @param overwrite (logical) by default, if the output path already exists, it will not be overwritten.
#' @param meta.js path to JSON file with metadata for PGV (should be located in "public/settings.json" inside the repository)
#' @param bin.width (integer) bin width for rebinning the coverage (default: 1e4)
#' @author Alon Shaiber
cov2arrowPGV = function(cov,
        field = "ratio",
        output_file = 'coverage.arrow',
        ref = 'hg19',
        cov.color.field = NULL,
        overwrite = TRUE,
        meta.js = NULL,
        ...){

    outdir = dirname(output_file)
    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)

    if (!file.exists(output_file) | overwrite){
        if (!requireNamespace("arrow", quietly = TRUE)) {
            stop('You must have the package "arrow" installed in order for this function to work. Please install it.')
        }

        message('Converting coverage format')
        dat = cov2cov.js(cov, meta.js = meta.js, js.type = 'PGV', field = field,
                         ref = ref, cov.color.field = cov.color.field, ...)
        message('Done converting coverage format')

        if (!is.null(cov.color.field)){
            dat[, color := color2numeric(get(cov.color.field))]
        } else {
            if (!is.null(meta.js)){
                ref_meta = get_ref_metadata_from_PGV_json(meta.js, ref)
                setkey(ref_meta, 'chromosome')
                dat$color = color2numeric(ref_meta[dat$seqnames]$color)
            } else {
                # no cov.color.field and no meta.js so set all colors to black
                dat$color = 0
            }
        }

        outdt = dat[, .(x = new.start, y = get(field), color)]

        # if there are any NAs for colors then set those to black
        outdt[is.na(color), color := 0]

        # remove NAs
        outdt = outdt[!is.na(y)]

        # sort according to x values (that is what PGV expects)
        outdt = outdt[order(x)]

        message('Writing arrow file (using write_feather)')
        arrow_table = arrow::Table$create(outdt, schema = arrow::schema(x = arrow::float32(), y = arrow::float32(), color = arrow::float32()))
        arrow::write_feather(arrow_table, output_file, compression="uncompressed")
    } else {
        message('arrow file, "', output_file, '" already exists.')
    }
    return(output_file)
}

#' @name grab.hets
#' @title grab.hets
#'
#' @description
#'
#' returns allele gtrack given sites.txt from het pileup
#'
#' @param agt.fname (character) path to sites.txt
#' @param min.frac (numeric) between 0 and 1, min frequency in normal to count as het site
#' @param max.frac (numeric) between 0 and 1, max frequency in normal to count as het site
#' 
#' @return allele gTrack
grab.hets = function(agt.fname = NULL,
                     min.frac = 0.2,
                     max.frac = 0.8)
{
    if (is.null(agt.fname) || !file.exists(agt.fname)) {
        stop("agt.fname does not exist")
    }

    ## prepare and filter
    agt.dt = fread(agt.fname)[alt.frac.n > min.frac & alt.frac.n < max.frac,]
    ## add major and minor
    agt.dt[, which.major := ifelse(alt.count.t > ref.count.t, "alt", "ref")]
    agt.dt[, major.count := ifelse(which.major == "alt", alt.count.t, ref.count.t)]
    agt.dt[, minor.count := ifelse(which.major == "alt", ref.count.t, alt.count.t)]

    ## melt the data frame
    agt.melted = rbind(agt.dt[, .(seqnames, start, end, count = major.count, allele = "major")],
                       agt.dt[, .(seqnames, start, end, count = minor.count, allele = "minor")]
                       )

    ## make GRanges
    agt.gr = dt2gr(agt.melted[, .(seqnames, start, end, count, allele)])

    return (agt.gr)
}

#' @name subsample_hetsnps
#' @title subsample_hetsnps
#' @description subsets the hetsnps to masked unique sites and colors by major/minor allele
#'
#' @param het_pileups_wgs sites.txt from het pileup
#' @param mask rds file with masked regions
#' @param sample_size number of snps to randomly sample
#' @export
#' @author Jonathan Rafailov, Shihab Dider
subsample_hetsnps = function(
    het_pileups_wgs,
    mask=NULL,
    sample_size = 100000
) {
    if (is.null(het_pileups_wgs)) {
        stop("het_pileups_wgs does not exist")
    }
    if (is.null(mask)) {
        warning("mask does not exist, using default mask included with package.")
        maska_path = system.file("extdata", "data", "maskA_re.rds", package = "Skilift")
        maska = readRDS(maska_path)
    }

    hets.gr <- grab.hets(het_pileups_wgs)
    hets.gr = gr.val(hets.gr, maska, "mask")
    hets.gr = hets.gr %Q% (is.na(mask))
    hets.gr$mask = NULL
    # lets call major blue and minor red
    hets.gr$col <- c("major" = "red", "minor" = "blue")[hets.gr$allele]

    #lets subset a random amount of SNPS so we're under 250k points
    unique.snps = unique(gr2dt(hets.gr)[,.(seqnames, start,end)])
    n_snps = nrow(unique.snps)
    message(paste(n_snps, "snps found"))
    message(paste("subsampling", sample_size, "points..."))
    snps.to.include = unique.snps[sample(n_snps, sample_size)] %>% dt2gr()
    subset.hets.gr = hets.gr %&% snps.to.include

    return(subset.hets.gr)
}


#' @description
#' Create coverage arrow plot JSON file.
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_cov_arrow = function(plot_metadata, datadir, settings) {
    cov_json_path <- file.path(
        datadir,
        plot_metadata$patient.id,
        plot_metadata$source
    )

    if (!("field" %in% names(plot_metadata))) {
        stop(warning("Please include a 'field' column which indicates the column name that contains the coverage data."))
    }

    # check if the input is a GRanges or a nested list
    is_list <- is(plot_metadata$x[[1]], "list")
    if (is_list) {
        plot_metadata$x <- plot_metadata$x[[1]]
    } 

    is_granges <- is(plot_metadata$x[[1]], "GRanges")
    is_path <- is(plot_metadata$x[[1]], "character")
    if (is_granges) {
        # save granges to a temp file and assign path to plot_metadata$x
        print("Saving GRanges to temp file")
        temp_file <- tempfile(fileext = ".rds")
        saveRDS(plot_metadata$x[[1]], temp_file)
        plot_metadata$x <- temp_file
    } else if (is_path) {
        plot_metadata$x <- plot_metadata$x[[1]]
    } else {
        stop(warning("Please provide a GRanges object or a path to a GRanges object."))
    }

    if (!file.exists(cov_json_path) || plot_metadata$overwrite) {
        if (file.exists(plot_metadata$x)) {
            cov2arrowPGV(plot_metadata$x,
                field = plot_metadata$field,
                meta.js = settings,
                ref = plot_metadata$ref,
                output_file = cov_json_path
            )
        } else {
            warning(
                paste0(
                    "Input coverage file does not exist for name: ",
                    plot_metadata$sample,
                    " so no coverage will be generated."
                )
            )
        }
    } else {
        message(cov_json_path, " already exists! Set overwrite = TRUE if you want to overwrite it.")
    }
}


#' @description
#' Add gGraph JSON file to PGV datafiles.json.
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_ggraph_json = function(plot_metadata, datadir, settings) {
    ggraph_json_path <- file.path(
        datadir,
        plot_metadata$patient.id,
        plot_metadata$source
    )
    if (!file.exists(ggraph_json_path) || plot_metadata$overwrite) {
        if (is(plot_metadata$x[[1]], "gGraph")) {
            ggraph <- plot_metadata$x[[1]]
        } else {
            message(paste0("reading in ", plot_metadata$x))
            if (grepl(plot_metadata$x, pattern = ".rds")) {
                ggraph <- readRDS(plot_metadata$x)
            } else {
                message("Expected .rds ending for gGraph. Attempting to read anyway: ", plot_metadata$x)
                ggraph <- readRDS(plot_metadata$x)
            }
        }
        if (any(class(ggraph) == "gGraph")) {
            seq_lengths <- gGnome::parse.js.seqlengths(
                settings,
                js.type = "PGV",
                ref = plot_metadata$ref
            )
            # check for overlap in sequence names
            ggraph.reduced <- ggraph[seqnames %in% names(seq_lengths)]
            if (length(ggraph.reduced) == 0) {
                stop(sprintf(
                    'There is no overlap between the sequence names in the reference
                    used by PGV and the sequences in your gGraph. Here is an
                    example sequence from your gGraph: "%s". And here is an
                    example sequence from the reference used by gGnome.js: "%s"',
                    seqlevels(ggraph$nodes$gr)[1], names(seq_lengths)[1]
                ))
            }
            #add maxcn from plot_metadata if exists
            if("max.cn" %in% colnames(plot_metadata)) {
                maxcn = plot_metadata$max.cn
            } else {
                maxcn = 100
            }
            # sedge.id or other field
            if("col" %in% names(mcols(ggraph$nodes$gr))) { 
                nfields = "col"
            } else {
                nfields = NULL
            }
            if ("annotation" %in% colnames(plot_metadata)) {
                annotations = unlist(plot_metadata$annotation)
            } else {
                annotations = NULL
            }
            ## if ("annotation" %in% colnames(plot_metadata)) {
            # probably check for other cid.field names?
            # field = 'sedge.id'
            gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
                filename = ggraph_json_path,
                verbose = TRUE,
                annotations = annotations,
                maxcn = maxcn,
                nfields = nfields
                # cid.field = field
            )
            ## } else {
            ##     gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
            ##                                                                   filename = ggraph_json_path,
            ##                                                                   verbose = TRUE,
            ##                                                                   maxcn = maxcn,
            ##                                                                   nfields = nfields
            ##                                                               )
            ## }
        } else {
            warning(plot_metadata$x, " rds read was not a gGraph")
        }
    } else {
        warning("file ", ggraph_json_path, "already exists. Set overwrite = TRUE if you want to overwrite it.")
    }
}

#' @description
#' Create allelic gGraph JSON file.
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_allelic_json = function(plot_metadata, datadir, settings) {
    ggraph_json_path <- file.path(
        datadir,
        plot_metadata$patient.id,
        plot_metadata$source
    )
    if (!file.exists(ggraph_json_path) || plot_metadata$overwrite) {
        if (is(plot_metadata$x[[1]], "gGraph")) {
            ggraph <- plot_metadata$x[[1]]
        } else {
            message(paste0("reading in ", plot_metadata$x))
            if (grepl(plot_metadata$x, pattern = ".rds")) {
                ggraph <- readRDS(plot_metadata$x)
            } else {
                message("Expected .rds ending for gGraph. Attempting to read anyway: ", plot_metadata$x)
                ggraph <- readRDS(plot_metadata$x)
            }
        }
        if (any(class(ggraph) == "gGraph")) {
            seq_lengths <- gGnome::parse.js.seqlengths(
                settings,
                js.type = "PGV",
                ref = plot_metadata$ref
            )
            # check for overlap in sequence names
            ggraph.reduced <- ggraph[seqnames %in% names(seq_lengths)]
            if (length(ggraph.reduced) == 0) {
                stop(sprintf(
                    'There is no overlap between the sequence names in the reference
                    used by PGV and the sequences in your gGraph. Here is an
                    example sequence from your gGraph: "%s". And here is an
                    example sequence from the reference used by gGnome.js: "%s"',
                    seqlevels(ggraph$nodes$gr)[1], names(seq_lengths)[1]
                ))
            }
            #add maxcn from plot_metadata if exists
            if("max.cn" %in% colnames(plot_metadata)) {
                maxcn = plot_metadata$max.cn
            } else {
                maxcn = 100
            }
            if ("annotation" %in% colnames(plot_metadata)) {
                annotations = unlist(plot_metadata$annotation)
            } else {
                annotations = NULL
            }


            # sedge.id or other field
            ## if ("annotation" %in% colnames(plot_metadata)) {
            # probably check for other cid.field names?
            # field = 'sedge.id'
            gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
                filename = ggraph_json_path,
                verbose = TRUE,
                annotations = annotations,
                maxcn = maxcn,
                nfields = "col",
                save = TRUE,
                offset = TRUE
                # cid.field = field
            )
            ## for(x in 1:length(gg.js$intervals)) {
            ##     col1 = gg.js$intervals[[x]]$metadata$color
            ##     if(gg.js$intervals[[x]]$y != 0) {
            ##         if(col1 == "#0000FF80") {
            ##             gg.js$intervals[[x]]$y = gg.js$intervals[[x]]$y + 0.1
            ##         } else if(col1 == "#FF000080") {
            ##             gg.js$intervals[[x]]$y = gg.js$intervals[[x]]$y - 0.1
            ##         }
            ##     }
            ## }

            ## } else {
            ##     gg.js = gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
            ##                                                                   verbose = TRUE,
            ##                                                                   maxcn = maxcn,
            ##                                                                   nfields = "col",
            ##                                                                   save = FALSE
            ##                                                                   )
            ##     ## filename = ggraph_json_path,
            ## }
            ##temporary fix for adding padding to allelic graphs for major and minor- should probably be implented into ggnome
            #major : "#0000FF80"
            #minor : "#FF000080"

        } else {
            warning(plot_metadata$x, " rds read was not a gGraph")
        }
    } else {
        warning("file ", ggraph_json_path, "already exists. Set overwrite = TRUE if you want to overwrite it.")
    }
}

#' @description
#' Create gWalk JSON file
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_gwalk_json = function(plot_metadata, datadir, settings) {
    gwalk_json_path <- file.path(datadir, plot_metadata$patient.id, plot_metadata$source)
    if (!file.exists(gwalk_json_path) || plot_metadata$overwrite == TRUE) {
        if (is(plot_metadata$x[[1]], "gWalk")) {
            gwalk <- plot_metadata$x[[1]] %>% gGnome::refresh()
        } else {
            message(paste0("reading in ", plot_metadata$x))
            if (grepl(plot_metadata$x, pattern = ".rds")) {
                gwalk <- readRDS(plot_metadata$x) %>% gGnome::refresh()
            } else {
                message("Expected .rds ending for gWalk Attempting to read anyway: ", plot_metadata$x)
                gwalk <- readRDS(plot_metadata$x) %>% gGnome::refresh()
            }
        }

        if (gwalk$length == 0) {
            warning(sprintf("Zero walks in gWalk .rds file provided for sample %s!
                No walks json will be produced!", plot_metadata$sample))
            return(NA)
        }

        gwalk$json(
            filename = gwalk_json_path, verbose = TRUE,
            annotations = unlist(plot_metadat$annotation),
            include.graph = FALSE
        )
    } else {
        message(gwalk_json_path, "already exists! Set overwrite = TRUE if you want to overwrite it.")
    }
}

#' @description
#' Create mutations gGraph JSON file.
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_somatic_json = function(plot_metadata, datadir, settings) {
    somatic_json_path <- file.path(
        datadir,
        plot_metadata$patient.id,
        plot_metadata$source
    )
    if (!file.exists(somatic_json_path) || plot_metadata$overwrite) {
        if (any(class(plot_metadata$x[[1]]) == "data.table")) {
            mutations.dt <- plot_metadata$x[[1]]
        } else {
            message(paste0("reading in ", plot_metadata$x))
            if (grepl(plot_metadata$x, pattern = ".rds")) {
                mutations.dt <- as.data.table(readRDS(plot_metadata$x))
            } else {
                message("Expected .rds ending for mutations. Attempting to read anyway: ", plot_metadata$x)
                mutations.dt <- as.data.table(readRDS(plot_metadata$x))
            }
        }
        if (any(class(mutations.dt) == "data.table")) {
            seq_lengths <- gGnome::parse.js.seqlengths(
                settings,
                js.type = "PGV",
                ref = plot_metadata$ref
            )
            # check for overlap in sequence names
            mutations.reduced <- mutations.dt[seqnames %in% names(seq_lengths),]
            if (length(mutations.reduced) == 0) {
                stop(sprintf(
                    'There is no overlap between the sequence names in the reference
                    used by PGV and the sequences in your mutations. Here is an
                    example sequence from your mutations: "%s". And here is an
                    example sequence from the reference used by gGnome.js: "%s"',
                    mutations$seqnames[1], names(seq_lengths)[1]
                ))
            }
            yfield = plot_metadata$field[1]
            mutations.dt = mutations.dt[!is.na(get(yfield)),]
            mutations.dt[start == end, end := end +1]
            mutations.dt[, strand := NULL]
            mutations.dt[variant.p != "",annotation := paste0("Type: ", annotation, "; Gene: ", gene, "; Variant: ",variant.c, "; Protein_variant: ", variant.p, "; VAF: ",VAF)]
            mutations.dt[variant.p == "",annotation := paste0("Type: ", annotation, "; Gene: ", gene, "; Variant: ",variant.c, "; VAF: ",VAF)]
            dt2json_mut(dt = mutations.dt, ref = plot_metadata$ref,settings = settings, meta_data = c("gene", "feature_type","annotation","REF","ALT","variant.c","variant.p","VAF","transcript_type", "impact","rank"), y_col = yfield, file_name = somatic_json_path)
        } else {
            warning(plot_metadata$x, " rds read was not mutations")
        }
    } else {
        warning("file ", ggraph_json_path, "already exists. Set overwrite = TRUE if you want to overwrite it.")
    }
}

#' @description
#' Create ppfit gGraph JSON file.
#'
#' @param plot_metadata data.table with Plot metadata, columns = (patient.id, source, x (contains path to data file or reference to data file object itself), ref, overwrite).
#' @param datadir Path to data directory with patient directories.
#' @param settings Path to settings.json file.
#'
#' @return NULL.
create_ppfit_genome_json = function(plot_metadata, datadir, settings) {
  ppfit_json_path <- file.path(
    datadir,
    plot_metadata$patient.id,
    plot_metadata$source
  )
  tryCatch({
    if (!file.exists(ppfit_json_path) || plot_metadata$overwrite) {
      if (is(plot_metadata$x[[1]], "list")) {
        ggraph <- plot_metadata$x[[1]]
      } else {
        message(paste0("reading in ", plot_metadata$x))
        if (grepl(plot_metadata$x, pattern = ".rds")) {
          ggraph <- readRDS(plot_metadata$x)
        } else {
          message("Expected .rds ending for gGraph. Attempting to read anyway: ", plot_metadata$x)
          ggraph <- readRDS(plot_metadata$x)
        }
      }
      if (any(class(ggraph) == "gGraph")) {
        seq_lengths <- gGnome::parse.js.seqlengths(
                                 settings,
                                 js.type = "PGV",
                                 ref = plot_metadata$ref
                               )
        colnames_check = c(
            "start_ix",
            "end_ix",
            "eslack_in",
            "eslack_out",
            "edges_in",
            "edges_out",
            "tile_id",
            "snode_id",
            "loose_left",
            "loose_right",
            "loose_cn_left",
            "loose_cn_right",
            "node_id",
            "raw_mean",
            "raw_var",
            "nbins",
            "nbins_tot",
            "nbins_nafrac",
            "wbins_nafrac",
            "wbins_ok",
            "mean",
            "bad",
            "max_na",
            "loess_var",
            "tau_sq_post",
            "post_var",
            "var",
            "sd"
        )

        if(all(colnames_check %in% names(ggraph$nodes$dt))) {
          ggraph2 = ggraph
          fields.keep = c(
              colnames_check,
              "seqnames",
              "start",
              "end",
              "strand",
              "width",
              "loose",
              "index"
          )
        } else {
          ## segstats information          
          segstats.dt = create_ppfit_json(
              jabba_gg = ggraph,
              path_obj = plot_metadata$x,
              return_table = TRUE,
              write_json = FALSE
          )
          segstats.gr = GRanges(segstats.dt, seqlengths = seq_lengths) %>% trim
          ggraph2 = gG(nodes = segstats.gr, edges = ggraph$edges$dt)
          fields.keep =names(segstats.dt) %>% grep("cn",.,invert = TRUE, value = TRUE)
        }
        ggraph2$set(y.field = "cn")
        ## check for overlap in sequence names
        ggraph.reduced <- ggraph2[seqnames %in% names(seq_lengths)]
        if (length(ggraph.reduced) == 0) {
          stop(sprintf(
            'There is no overlap between the sequence names in the reference
                    used by PGV and the sequences in your gGraph. Here is an
                    example sequence from your gGraph: "%s". And here is an
                    example sequence from the reference used by gGnome.js: "%s"',
            seqlevels(ggraph.reduced$nodes$gr)[1], names(seq_lengths)[1]
          ))
        }
                                        # sedge.id or other field
        if ("annotation" %in% colnames(plot_metadata)) {
                                        # probably check for other cid.field names?
                                        # field = 'sedge.id'
          ## gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
          gGnome::refresh(ggraph.reduced)$json(
                                            filename = ppfit_json_path,
                                            verbose = TRUE,
                                            annotations = unlist(plot_metadata$annotation),
                                            maxcn = 500,
                                            nfields = fields.keep,
                                            save = TRUE
                                        # cid.field = field
                                          )
        } else {
          ## gGnome::refresh(ggraph[seqnames %in% names(seq_lengths)])$json(
          gGnome::refresh(ggraph.reduced)$json(
                                            filename = ppfit_json_path,
                                            verbose = TRUE,
                                            maxcn = 500,
                                            nfields = fields.keep,
                                            save = TRUE
                                          )
        }
      } else {
        warning(plot_metadata$x, " rds read was not a gGraph")
      }
    } else {
      warning("file ", ppfit_json_path, "already exists. Set overwrite = TRUE if you want to overwrite it.")
    }
  }, error = function(e) {
    message("Error in creating ppfit plot for sample: ",plot_metadata$patient.id, "\n JaBbA:::segstats needs to be run or provided first")
    print(e)
  })
}

#' @name create_somatic_json
#' @title create_somatic_json
#' @description
#'
#' @param somatic_snv_cn somatic copy number data table
#' @param out_file where the json should be written
#' @param pair patient.id to be used for pgvdb or case reports
#' @param pgv_settings the settings file used for pgvdb or case reports
#' @param return_table_pgv TRUE/FALSE whether to return the data.table to add to pgvdb
#' @param meta_keep meta data to write in the json
#' @param y_col column to be used for y axis values
#' @return data.table to add to pgv or NULL, depends on return_table_pgv
#' @export
#' @author Stanley Clarke
## create_somatic_json = function(somatic_snv_cn, out_file, pair, pgv_settings, return_table_pgv = FALSE, meta_keep = NULL, y_col = "est_cn_llrm", ref = "hg19") {
##     som.dt = readRDS(somatic_snv_cn)
##     som.dt = som.dt[!is.na(get(y_col)),]
##     som.dt[start == end, end := end +1]
##     som.dt[, strand := NULL]
##     som.dt[variant.p != "",annotation := paste0("Type: ", annotation, "; Gene: ", gene, "; Variant: ",variant.c, "; Protein_variant: ", variant.p, "; VAF: ",vaf)]
##     som.dt[variant.p == "",annotation := paste0("Type: ", annotation, "; Gene: ", gene, "; Variant: ",variant.c, "; VAF: ",vaf)]
##     dt2json_mut(dt = som.dt, ref = ref,settings = pgv_settings, meta_data = meta_keep, y_col = y_col,
##                 file_name = out_file)
##     if(return_table_pgv) {
##         dt.add = data.table(patient.id = pair, type = "genome",visible = TRUE, title = "Copy Number Mutations", source = "mutations.json")
##     }
## }

#' @name dt2json_mut
#' @title dt2json_mut
#' @description
#'
#' function to create a mutation json, used in create_somatic_json
#' 
#' @param dt data.table with seqnames,start and end
#' @param patient.id patient id to be added to pgvdb or case reports
#' @param ref reference for pgv or case reports
#' @param file_name the file the json should be written to
#' @param meta_data extra information to add to the json
#' @param y_col column to be used for y axis values
#' @return NULL
#' @export
#' @author Stanley Clarke
dt2json_mut = function(dt,patient.id,ref,settings,file_name = paste(getwd(),"test.json",sep="/"), meta_data = NULL, y_col = NULL) {
    #create vector of seqlengths
    settings_data <- jsonlite::fromJSON(settings)
    chrom_lengths <- as.data.table(settings_data$coordinates$sets[[ref]])[,.(chromosome,startPoint,endPoint)]
    colnames(chrom_lengths) = c("seqnames","start","end")

    if(nrow(chrom_lengths[grepl("chr",seqnames),]) > 0) {
        chrom_lengths[!grepl("chr",seqnames), seqnames := paste0("chr",seqnames)] # weird fix because hg38_chr does not have chr on Y and M
    }
                                        #add y value specified
    if(is.null(y_col)) {
        dt$y_value = 1
    } else {
        dt[,y_value := get(y_col)]
    }
#convert to ggraph and create json
    if(nrow(chrom_lengths[grepl("chr",seqnames),]) > 0) {
        gr1 = dt2gr(dt[order(seqnames,start),]) %>% sortSeqlevels() %>% gr.chr()
    } else {
        gr1 = dt2gr(dt[order(seqnames,start),]) %>% sortSeqlevels() %>% gr.nochr()
    }
    if(any(gr1@seqinfo@seqlengths > chrom_lengths[seqnames %in% names(seqlengths(gr1))]$end)) {
        stop(paste("the seqlengths of your granges has ranges that are not contained in the seqlengths of",ref))
    }
    jab = gG(nodes=gr1)
    settings_y = list(y_axis = list(title = "copy number",
                                    visible = TRUE))
    node.dt = gr2dt(jab$nodes$gr[, c("snode.id","y_value",meta_data)])
    node.json = node.dt[, .(chromosome = seqnames, startPoint = start, endPoint = end, iid = snode.id,title=snode.id,type="interval", y = y_value, annotation = node.dt$annotation)]
    gg.js = list(intervals = node.json, connections = data.table())
    gg.js = c(list(settings = settings_y), gg.js)
    message(paste0("Writing json to ",file_name))
    jsonlite::write_json(gg.js, file_name,
                         pretty=TRUE, auto_unbox=TRUE, digits=4)
}


#' @name create_oncotable
#' @title create_oncotable
#' @description
#'
#' function to create oncotable for use with filtered_events_json
#' 
#' @param pair patient id 
#' @param annotated_bcf bcf with variant annotations (snpeff)
#' @param signature_counts output of Signatures task (optional)
#' @param jabba_simple jabba.simple.rds from JaBbA
#' @param fusions output of fusions task
#' @param events output of events task 
#' @param gencode file to gencode annotations (uses v29lift37 by default)
#' @param amp_thresh_multiplier amp.thresh for oncotable is amp_thresh_multiplier*ploidy
#' @param outdir path to directory in which to write oncotable outputs
#' @return data.table or NULL
#' @export
#' @author Shihab Dider, Joel Rosiene
create_oncotable = function(
    pair,
    annotated_bcf,
    signature_counts = NULL,
    fusions,
    jabba_simple,
    events,
    gencode = NULL,
    amp_thresh_multiplier = NULL,
    outdir
) {
    tumors = data.table(
      id = pair,
      annotated_bcf = annotated_bcf,
      signature_counts = signature_counts,
      fusions = fusions,
      jabba_rds = jabba_simple,
      complex = events
    )
    setkey(tumors, id)

    if (system("which bcftools", intern = TRUE) == "") {
      stop("bcftools is not available on the system PATH. Try `module load htslib` first or install it.")
    } else {
      message("bcftools is available.")
    }

    if (is.null(gencode)) {
        warning("path to gencode was not passed, setting to default ~/DB/GENCODE/gencode.v29lift37.annotation.nochr.rds")
        gencode = "~/DB/GENCODE/gencode.v29lift37.annotation.nochr.rds"
    }

    if (is.null(amp_thresh_multiplier)) {
        warning("amp_thres_multiplier was not passed, setting to default 1.5")
        amp_thresh_multiplier = 1.5
    }

    ploidy = readRDS(jabba_simple)$ploidy
    amp_thresh = amp_thresh_multiplier*ploidy
    message(paste("using amp.thresh of", amp_thresh))

    oncotable = skitools::oncotable(
      tumors,
      gencode = gencode,
      filter = "PASS",
      verbose = TRUE,
      amp.thresh=amp_thresh
    )

    if (!dir.exists(outdir)) {
        dir.create(outdir, recursive=TRUE)
    }

    saveRDS(oncotable, paste0(outdir, "/", "oncotable.rds"))
    fwrite(oncotable, paste0(outdir, "/", "oncotable.txt"))
}

#' @name filtered_events_json
#' @title filtered_events_json
#' @description
#'
#' function to create filtered events json for case reports
#' 
#' @param pair patient id to be added to pgvdb or case reports
#' @param oncotable oncotable task output
#' @param jabba_gg JaBbA output ggraph or complex
#' @param out_file path to write json
#' @param cgc_file path to cgc file to annotate drivers
#' @param return_table TRUE/FALSE whether to return the data.table that is used for creating the json
#' @return data.table or NULL
#' @export
#' @author Stanley Clarke, Tanubrata Dey

filtered_events_json = function(pair, oncotable, jabba_gg, out_file, cgc_file = "/gpfs/commons/groups/imielinski_lab/DB/COSMIC/v99_GRCh37/cancer_gene_census_fixed.csv", temp_fix = FALSE,return_table = FALSE) {
    ##Driver CNA windows
    ##Load details from oncotable
    ot = readRDS(oncotable)
    snvs = ot[grepl('frameshift|missense|stop|disruptive', annotation)]
    snvs = snvs[!duplicated(variant.p)]
    ##Note here probably have to crossreference these missense muts with hetdels
    #hetdel_snvs = snvs[gene %in% ot[type == 'hetdel',gene]]
                                        #possible_drivers = rbind(hetdel_snvs,homdels)
    homdels = ot[type == 'homdel']
    amps = ot[type == 'amp']
    jab = readRDS(jabba_gg)
    possible_drivers = rbind(snvs,homdels,amps)
    cgc = fread(cgc_file)
    names(cgc) = gsub(' ','.', names(cgc))
    cgc$gene = cgc$Gene.Symbol
    ## longlist = merge.data.table(possible_drivers, cgc, by = 'gene', all.x = TRUE)
    longlist = merge.data.table(possible_drivers, cgc, by = 'gene')
    res = longlist[ ,.(gene, id, type, variant.p, Name, Genome.Location, Tier, Role.in.Cancer)]
    names(res) = c("gene", "id", "type", "Variant", "Name", "Genome_Location", "Tier", "Role_in_Cancer")
                                        #add copy number to homdels
    res = res %>% unique
    if(nrow(res) > 0) {
        res[,seqnames := tstrsplit(Genome_Location,":",fixed=TRUE,keep=1)]
        res[,start := tstrsplit(Genome_Location,"-",fixed=TRUE,keep=1)]
        res[,start := tstrsplit(start,":",fixed=TRUE,keep=2)]
        res[,end := tstrsplit(Genome_Location,"-",fixed=TRUE,keep=2)]
        res.mut = res[!is.na(Variant),]
        if(nrow(res.mut) > 0) {
            res.mut[,Variant := gsub("p.","",Variant)]
        }
        res.cn = res[is.na(Variant),]
        if(nrow(res.cn) >0) {
            res.cn.gr = GRanges(res.cn)
            res.cn.gr = gr.val(res.cn.gr,jab$nodes$gr,c("cn","cn.low","cn.high"))
            res.cn.dt = as.data.table(res.cn.gr)
            res.cn.dt[!is.na(cn) & !is.na(cn.low) & !is.na(cn.high), Variant := paste0("Total CN:",round(cn,digits = 3),"; CN Minor:",round(cn.low,digits = 3),"; CN Major:",round(cn.high,digits = 3))]
            res.cn.dt[!is.na(cn) & is.na(cn.low) & is.na(cn.high), Variant := paste0("Total CN:",round(cn,digits = 3))]
            if(temp_fix) {
                res.cn.dt = res.cn.dt[!(type == "homdel" & cn != 0),]
                res.cn.dt = res.cn.dt[!(type == "amp" & cn <= 2),]
            }
            res.cn.dt[,c("cn", "cn.high", "cn.low", "width", "strand") := NULL] #make null, already added to Variant
            res.final = rbind(res.mut,res.cn.dt)
        } else {
            res.final = res.mut
            res.final[,c("seqnames", "start", "end") := NULL]
        }
        message(paste0("Writing json to ",out_file))
        write_json(res.final, out_file, pretty=TRUE)
        res.final[,sample := pair]
        if(return_table) {
            return(res.final)
        }
    }
}

#' @name strelka2counts
#' @title strelka2counts
#' @description
#' takes in a strelka vcf and returns a data.table with total count and count of variants with normal vaf greater than 0
#' 
#' @param vcf patient id to be added to pgvdb or case reports
#' @param seqnames_genome_width chromosomes to count variants in
#' @param type_return counts or dt, if counts returns counts for snv and snv count with a normal vaf greater than 0. If dt, returns the parsed vcf
#' @return data.table
#' @export
#' @author Stanley Clarke, Tanubrata Dey
strelka2counts = function(vcf, seqnames_genome_width = c(1:22,"X","Y"), type_return = "counts") {
    somatic.filtered.vcf = read.delim(vcf,header=F,comment.char='#',col.names=c("CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO","FORMAT","NORMAL","TUMOR")) %>% as.data.table
    ##strip chr
    somatic.filtered.vcf[, CHROM := gsub("chr","",CHROM)]
    ##
    sub.vcf = somatic.filtered.vcf[CHROM %in% seqnames_genome_width,]
    sub.vcf[, c("DP", "FDP", "SDP", "SUBDP", "AU", "CU", "GU", "TU","INDEL") := tstrsplit(NORMAL, ":", fixed = TRUE)]
    sub.vcf[REF == "A" & ALT == "T", c("ref_count","alt_count") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "A" & ALT == "C", c("ref_count","alt_count") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "A" & ALT == "G", c("ref_count","alt_count") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "T", c("ref_count","alt_count") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "A", c("ref_count","alt_count") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "G", c("ref_count","alt_count") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "T", c("ref_count","alt_count") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "C", c("ref_count","alt_count") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "A", c("ref_count","alt_count") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "A", c("ref_count","alt_count") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "C", c("ref_count","alt_count") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "G", c("ref_count","alt_count") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[, c("DP", "DP2", "TAR", "TIR", "TOR", "DP50", "FDP50", "SUBDP50", "BCN50") := tstrsplit(NORMAL, ":", fixed = TRUE)]
    sub.vcf[is.na(ref_count), ref_count := tstrsplit(TAR, ",", fixed = TRUE, keep = 1)]
    sub.vcf[is.na(alt_count), alt_count := tstrsplit(TIR, ",", fixed = TRUE, keep = 1)]
    sub.vcf[, ref_count := as.numeric(ref_count)]
    sub.vcf[, alt_count := as.numeric(alt_count)]
    sub.vcf[, normal_vaf := alt_count / (ref_count + alt_count)]
    ##now tumor vaf
    sub.vcf[, c("DP", "FDP", "SDP", "SUBDP", "AU", "CU", "GU", "TU","INDEL") := tstrsplit(TUMOR, ":", fixed = TRUE)]
    sub.vcf[REF == "A" & ALT == "T", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "A" & ALT == "C", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "A" & ALT == "G", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(AU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "T", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "A", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "C" & ALT == "G", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(CU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "T", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(TU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "C", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "G" & ALT == "A", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(GU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "A", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(AU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "C", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(CU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[REF == "T" & ALT == "G", c("ref_count_tumor","alt_count_tumor") := c(tstrsplit(TU, ",", fixed = TRUE, keep = 1), tstrsplit(GU, ",", fixed = TRUE, keep = 1)),]
    sub.vcf[, c("DP", "DP2", "TAR", "TIR", "TOR", "DP50", "FDP50", "SUBDP50", "BCN50") := tstrsplit(TUMOR, ":", fixed = TRUE)]
    sub.vcf[is.na(ref_count_tumor), ref_count_tumor := tstrsplit(TAR, ",", fixed = TRUE, keep = 1)]
    sub.vcf[is.na(alt_count_tumor), alt_count_tumor := tstrsplit(TIR, ",", fixed = TRUE, keep = 1)]
    sub.vcf[, ref_count_tumor := as.numeric(ref_count_tumor)]
    sub.vcf[, alt_count_tumor := as.numeric(alt_count_tumor)]
    sub.vcf[, tumor_vaf := alt_count_tumor / (ref_count_tumor + alt_count_tumor)]
    if(type_return == "counts") {
        snv_count = nrow(sub.vcf)
        snv_count_normal_vaf_greater0 = nrow(sub.vcf[normal_vaf > 0,])
        return(data.table(category = c("snv_count","snv_count_normal_vaf_greater0"),
                          counts = c(snv_count, snv_count_normal_vaf_greater0)))
    } else if (type_return == "dt") {
        return(sub.vcf)
    }
}


#' @name parse_vcf_strelka2
#' @title parse_vcf_strelka2
#' @description
#' takes in a strelka vcf and returns a data.table format of the vcf file with required fields for strelka_qc function
#' 
#' @param vcf patient id to be added to pgvdb or case reports
#' @param seqnames_genome_width chromosomes to count variants in
#' @return data.table
#' @export
#' @author Tanubrata Dey, Stanley Clarke
parse_vcf_strelka2 = function(vcf, seqnames_genome_width = c(1:22,"X","Y")) {                                                                                                          
    somatic.filtered.vcf = read.delim(vcf,header=F,comment.char='#',col.names=c("CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO","FORMAT","NORMAL","TUMOR")) %>% as.data.table
    ##strip chr                                                                                                                                                                    
    somatic.filtered.vcf[, CHROM := gsub("chr","",CHROM)]                                                                                                                          
    ## normal counts and VAF                                                                                                                                                                            
    sub.vcf = somatic.filtered.vcf[CHROM %in% seqnames_genome_width,]                                                                                                              
    sub.vcf[, somatic_EVS := as.numeric(gsub(".*SomaticEVS=([^;]+).*", "\\1", INFO))]                                                                                              
    sub.vcf[, MQ := as.numeric(gsub(".*MQ=([^;]+).*", "\\1", INFO))]                                                                                                               
    sub.vcf[, c("N_DP", "N_FDP", "N_SDP", "N_SUBDP", "N_AU", "N_CU", "N_GU", "N_TU","N_INDEL") := tstrsplit(NORMAL, ":", fixed = TRUE)]                                            
    sub.vcf[REF == "A" & ALT == "T", c("ref_count_N","alt_count_N") := c(tstrsplit(N_AU, ",", fixed = TRUE, keep = 1), tstrsplit(N_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "A" & ALT == "C", c("ref_count_N","alt_count_N") := c(tstrsplit(N_AU, ",", fixed = TRUE, keep = 1), tstrsplit(N_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "A" & ALT == "G", c("ref_count_N","alt_count_N") := c(tstrsplit(N_AU, ",", fixed = TRUE, keep = 1), tstrsplit(N_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "T", c("ref_count_N","alt_count_N") := c(tstrsplit(N_CU, ",", fixed = TRUE, keep = 1), tstrsplit(N_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "A", c("ref_count_N","alt_count_N") := c(tstrsplit(N_CU, ",", fixed = TRUE, keep = 1), tstrsplit(N_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "G", c("ref_count_N","alt_count_N") := c(tstrsplit(N_CU, ",", fixed = TRUE, keep = 1), tstrsplit(N_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "T", c("ref_count_N","alt_count_N") := c(tstrsplit(N_GU, ",", fixed = TRUE, keep = 1), tstrsplit(N_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "C", c("ref_count_N","alt_count_N") := c(tstrsplit(N_GU, ",", fixed = TRUE, keep = 1), tstrsplit(N_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "A", c("ref_count_N","alt_count_N") := c(tstrsplit(N_GU, ",", fixed = TRUE, keep = 1), tstrsplit(N_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "A", c("ref_count_N","alt_count_N") := c(tstrsplit(N_TU, ",", fixed = TRUE, keep = 1), tstrsplit(N_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "C", c("ref_count_N","alt_count_N") := c(tstrsplit(N_TU, ",", fixed = TRUE, keep = 1), tstrsplit(N_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "G", c("ref_count_N","alt_count_N") := c(tstrsplit(N_TU, ",", fixed = TRUE, keep = 1), tstrsplit(N_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[, c("N_DP", "N_DP2", "N_TAR", "N_TIR", "N_TOR", "N_DP50", "N_FDP50", "N_SUBDP50", "N_BCN50") := tstrsplit(NORMAL, ":", fixed = TRUE)]                                  
    sub.vcf[is.na(ref_count_N), ref_count_N := tstrsplit(N_TAR, ",", fixed = TRUE, keep = 1)]                                                                                      
    sub.vcf[is.na(alt_count_N), alt_count_N := tstrsplit(N_TIR, ",", fixed = TRUE, keep = 1)]                                                                                      
    sub.vcf[, ref_count_N := as.numeric(ref_count_N)]                                                                                                                              
    sub.vcf[, alt_count_N := as.numeric(alt_count_N)]                                                                                                                              
    sub.vcf[, VAF_N := alt_count_N / (ref_count_N + alt_count_N)]                                                                                                                  
    sub.vcf[, c("N_FDP","N_SDP","N_SUBDP","N_AU","N_CU","N_GU","N_TU","N_INDEL","N_DP2","N_TAR","N_TIR","N_TOR","N_DP50","N_FDP50","N_SUBDP50","N_BCN50")] = NULL                  
    ## tumor counts and VAF                                                                                                                                                       
    sub.vcf[, c("T_DP", "T_FDP", "T_SDP", "T_SUBDP", "T_AU", "T_CU", "T_GU", "T_TU","T_INDEL") := tstrsplit(TUMOR, ":", fixed = TRUE)]                                             
    sub.vcf[REF == "A" & ALT == "T", c("ref_count_T","alt_count_T") := c(tstrsplit(T_AU, ",", fixed = TRUE, keep = 1), tstrsplit(T_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "A" & ALT == "C", c("ref_count_T","alt_count_T") := c(tstrsplit(T_AU, ",", fixed = TRUE, keep = 1), tstrsplit(T_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "A" & ALT == "G", c("ref_count_T","alt_count_T") := c(tstrsplit(T_AU, ",", fixed = TRUE, keep = 1), tstrsplit(T_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "T", c("ref_count_T","alt_count_T") := c(tstrsplit(T_CU, ",", fixed = TRUE, keep = 1), tstrsplit(T_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "A", c("ref_count_T","alt_count_T") := c(tstrsplit(T_CU, ",", fixed = TRUE, keep = 1), tstrsplit(T_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "C" & ALT == "G", c("ref_count_T","alt_count_T") := c(tstrsplit(T_CU, ",", fixed = TRUE, keep = 1), tstrsplit(T_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "T", c("ref_count_T","alt_count_T") := c(tstrsplit(T_GU, ",", fixed = TRUE, keep = 1), tstrsplit(T_TU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "C", c("ref_count_T","alt_count_T") := c(tstrsplit(T_GU, ",", fixed = TRUE, keep = 1), tstrsplit(T_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "G" & ALT == "A", c("ref_count_T","alt_count_T") := c(tstrsplit(T_GU, ",", fixed = TRUE, keep = 1), tstrsplit(T_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "A", c("ref_count_T","alt_count_T") := c(tstrsplit(T_TU, ",", fixed = TRUE, keep = 1), tstrsplit(T_AU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "C", c("ref_count_T","alt_count_T") := c(tstrsplit(T_TU, ",", fixed = TRUE, keep = 1), tstrsplit(T_CU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[REF == "T" & ALT == "G", c("ref_count_T","alt_count_T") := c(tstrsplit(T_TU, ",", fixed = TRUE, keep = 1), tstrsplit(T_GU, ",", fixed = TRUE, keep = 1)),]             
    sub.vcf[, c("T_DP", "T_DP2", "T_TAR", "T_TIR", "T_TOR", "T_DP50", "T_FDP50", "T_SUBDP50", "T_BCN50") := tstrsplit(TUMOR, ":", fixed = TRUE)]                                   
    sub.vcf[is.na(ref_count_T), ref_count_T := tstrsplit(T_TAR, ",", fixed = TRUE, keep = 1)]                                                                                      
    sub.vcf[is.na(alt_count_T), alt_count_T := tstrsplit(T_TIR, ",", fixed = TRUE, keep = 1)]                                                                                      
    sub.vcf[, ref_count_T := as.numeric(ref_count_T)]                                                                                                                              
    sub.vcf[, alt_count_T := as.numeric(alt_count_T)]                                                                                                                              
    sub.vcf[, VAF_T := alt_count_T / (ref_count_T + alt_count_T)]                                                                                                                  
    sub.vcf[, c("T_FDP","T_SDP","T_SUBDP","T_AU","T_CU","T_GU","T_TU","T_INDEL","T_DP2","T_TAR","T_TIR","T_TOR","T_DP50","T_FDP50","T_SUBDP50","T_BCN50")] = NULL                  
    return(sub.vcf)                                                                                                                                                                
}


#' @name strelka_qc
#' @title strelka_qc
#' @description
#'
#' function to create json for strelka qc plotting in case reports
#' 
#' @param path to strelka2 vcf file to be used 
#' @param chromosomes to select for. default: c(1:22,"X","Y")
#' @param outfile path to write json
#' @param write_json TRUE/FALSE whether to write the json
#' @param return_table TRUE/FALSE whether to return the data
#' @return NULL
#' @export 
#' @author Tanubrata Dey
strelka_qc = function(vcf, seqnames_genome_width = c(1:22,"X","Y"), outfile, write_json = TRUE, return_table = TRUE) {
    sq = parse_vcf_strelka2(vcf, seqnames_genome_width = seqnames_genome_width) %>% dplyr::select(CHROM,POS,REF,ALT,FILTER,T_DP,N_DP, alt_count_N, alt_count_T, MQ,VAF_T, somatic_EVS)
    names(sq) = c("chromosome", "position", "reference", "alternate", "filter","tumor_depth", "normal_depth", "normal_alt_counts", "tumor_alt_counts","mapping_quality", "tumor_VAF", "somatic_EVS")
    consider_numeric = c("tumor_depth", "normal_depth", "normal_alt_counts", "tumor_alt_counts","mapping_quality", "tumor_vaf", "somatic_EVS")
    sq[, (consider_numeric) := lapply(.SD, as.numeric), .SDcols = consider_numeric]
    sq[, id := .I]
    if(write_json) {
    ##write the json
        message(paste0("Writing json to ",outfile))
        write_json(sq,outfile,pretty = TRUE)
        if(return_table) {
            return(sq)
        }

    } else {
        return(sq)
    }
}

#' @name sage_count
#' @title sage_count
#' @description
#' takes in a SAGE vcf and returns a data.table with total count and count of variants with normal vaf greater than 0
#' 
#' @param vcf_path Path to the SAGE VCF file
#' @param genome Reference genome name (e.g., "hg19", "hg38")
#' @return data.table
#' @export
#' @author Shihab Dider, Tanubrata Dey
sage_count = function(
    vcf_path,
    genome
) {
    vcf = readVcf(vcf_path, genome)

    # Filter for PASS variants
    pass_variants = rowRanges(vcf)$FILTER == "PASS"
    vcf = vcf[pass_variants, ]

    snv_count = length(vcf)

    # Extract VAF_N from the genotype (geno) slot
    geno_data = geno(vcf)
    normal = colnames(geno_data$DP)[1]
    tumor = colnames(geno_data$DP)[2]

    if (normal %in% colnames(geno_data$DP)) {
        VAF_N = as.numeric(geno_data$AF[, normal])
        snv_count_normal_vaf_greater0 = sum(VAF_N > 0, na.rm = TRUE)
        return(data.table(category = c("snv_count", "snv_count_normal_vaf_greater0"),
            counts = c(snv_count, snv_count_normal_vaf_greater0)))
    } else {
        print("Tumor only run VCF provided, no VAF_N present.")
        return(data.table(category = c("snv_count", "snv_count_normal_vaf_greater0"),
            counts = c(snv_count, NA)))
    }
}


#' @name sage_qc
#' @title sage_qc
#' @description
#'
#' function to create json for sage qc plotting in case reports
#' 
#' @param vcf_path Path to sage VCF file to be used (paired T-N/ Tumor only)
#' @param genome Reference genome name (e.g., "hg19", "hg38")
#' @param outfile Path to write JSON
#' @param write_json TRUE/FALSE whether to write the JSON
#' @param return_table TRUE/FALSE whether to return the data
#' @return NULL
#' @export 
#' @author Shihab Dider, Tanubrata Dey, Stanley Clarke
sage_qc = function(
    vcf_path,
    genome,
    outfile,
    write_json = TRUE,
    return_table = TRUE
) {
    vcf = readVcf(vcf_path, genome)

    # Filter for PASS variants
    pass_variants = rowRanges(vcf)$FILTER == "PASS"
    vcf = vcf[pass_variants, ]

    # Extract necessary information from VCF object
    chrom = as.character(seqnames(rowRanges(vcf)))
    pos = start(rowRanges(vcf))
    ref = as.character(ref(vcf))
    alt = as.character(unlist(alt(vcf)))
    filter = as.character(rowRanges(vcf)$FILTER)
    qual = as.numeric(rowRanges(vcf)$QUAL)

    # Extract depth and allele count information from the genotype (geno) slot
    geno_data = geno(vcf)
    normal = colnames(geno_data$DP)[1]
    tumor = colnames(geno_data$DP)[2]

    T_DP = as.numeric(geno_data$DP[, tumor])
    alt_count_T = sapply(geno_data$AD[, tumor], function(x) as.numeric(x[2]))  # Extract the second element for alternate allele depth
    T_ABQ = as.numeric(geno_data$ABQ[, tumor])
    VAF_T = as.numeric(geno_data$AF[, tumor])

    # Check if normal sample data exists
    if (normal %in% colnames(geno_data$DP)) {
        N_DP = as.numeric(geno_data$DP[, normal])
        alt_count_N = sapply(geno_data$AD[, normal], function(x) as.numeric(x[2]))  # Extract the second element for alternate allele depth
        VAF_N = as.numeric(geno_data$AF[, normal])

        sq = data.table(
            chromosome = chrom,
            position = pos,
            reference = ref,
            alternate = alt,
            filter = filter,
            mapping_quality = qual,
            tumor_depth = T_DP,
            normal_depth = N_DP,
            normal_alt_counts = alt_count_N,
            tumor_alt_counts = alt_count_T,
            tumor_abq = T_ABQ,
            tumor_vaf = VAF_T,
            normal_vaf = VAF_N
        )

        consider_numeric = c("tumor_depth", "normal_depth", "normal_alt_counts", "tumor_alt_counts", "tumor_abq", "tumor_vaf", "normal_vaf")
    } else {
        sq = data.table(
            chromosome = chrom,
            position = pos,
            reference = ref,
            alternate = alt,
            filter = filter,
            mapping_quality = qual,
            tumor_depth = T_DP,
            tumor_alt_counts = alt_count_T,
            tumor_abq = T_ABQ,
            tumor_vaf = VAF_T
        )

        consider_numeric = c("tumor_depth", "tumor_alt_counts", "tumor_abq", "tumor_vaf")
    }

    sq[, (consider_numeric) := lapply(.SD, as.numeric), .SDcols = consider_numeric]
    sq[, id := .I]

    if(write_json) {
        message(paste0("Writing json to ", outfile))
        write_json(sq, outfile, pretty = TRUE)
        if(return_table) {
            return(sq)
        }
    } else {
        return(sq)
    }
}

#' @name dlrs
#' @title derivative log ratio spread
#' @description
#'
#' function to get the dlrs for coverage data
#' used in meta_data_json
#' 
#' @param x foreground from dryclean
#' @return dlrs
#' @export
#' @author Joel Rosiene
dlrs = function(x) {
    nx = length(x)
    if (nx<3) {
        stop("Vector length>2 needed for computation")
    }
    tmp = embed(x,2)
    diffs = tmp[,2]-tmp[,1]
    dlrs = IQR(diffs,na.rm=TRUE)/(sqrt(2)*1.34)
    return(dlrs)
}


#' @name create_mutations_catalog_json
#' @title create_mutations_catalog_json
#' @description
#'
#' Builds the mutations catalog for case reports using the output of sigprofiler matrix generator
#' 
#' @param sig_matrix_path Path to either the SBS or ID matrix
#' @param is_indel Boolean to indicate if the matrix is for indels
#' @param output_dir directory to write the jsons, will create directory for each patient id
#' @return 
#' @export
#' @author Shihab Dider, Sukanya Panja
create_mutations_catalog_json = function(
    sig_matrix_path,
    is_indel,
    output_dir
) {
    sig_matrix = fread(sig_matrix_path)
    sig_matrix_dt = as.data.frame(sig_matrix)
    samples = colnames(sig_matrix_dt)
    for(i in 2:(ncol(sig_matrix_dt))) { # skip first column as it has the tnc
        pair = samples[i]

        if (is_indel) {
            samp_data = data.frame(
                id = 1:nrow(sig_matrix_dt),
                insdel = sig_matrix_dt[, 1],
                mutations = sig_matrix_dt[,i]
            )
            catalog_file_name = "id_mutation_catalog.json"
        } else {
            samp_data = data.frame(
                id = 1:nrow(sig_matrix_dt),
                tnc = sig_matrix_dt[, 1],
                mutations = sig_matrix_dt[,i]
            )
            catalog_file_name = "mutation_catalog.json"
        }
        pair_data <- list(pair = pair, data = samp_data)
        system(paste("mkdir -p", paste0(output_dir, "/", pair)))
        output_path = paste0(output_dir, "/", catalog_file_name)
        write_json(
            pair_data,
            output_path,
            pretty=TRUE,
            auto_unbox=TRUE
        )
    }
}

#' @name meta_data_json
#' @title meta_data_json
#' @description
#'
#' function to create the meta data summary json for case reports
#' 
#' @param pair patient id to be added to pgvdb or case reports
#' @param out_file path to write json
#' @param coverage path dryclean coverage output
#' @param jabba_gg path to JaBbA output ggraph or complex
#' @param strelka2_vcf path to strelka vcf to get snv count
#' @param sage_vcf path to SAGE vcf to get snv count (if present)
#' @param svaba_somatic_vcf path to svaba somatic vcf for getting sv count
#' @param tumor_type_final tumor type abbreviation of the sample
#' @param disease full length tumor type
#' @param primary_site primary site of tumor
#' @param inferred_sex sex of the patient
#' @param karyograph JaBbA outputted karygraph
#' @param indel_sigprofiler path to Assignment_Solution_Activities.txt, output of sigprofiler
#' @param sbs_deconstructSigs path to rds output from deconstructSigs
#' @param sbs_sigprofiler path to Assignment_Solution_Activities.txt, output of sigprofiler 
#' @param seqnames_loh chromosomes to be used to calculate LOH
#' @param seqnames_genome_width chromosomes to be used to calculate tmb
#' @param write_json TRUE/FALSE to write the json
#' @param overwrite TRUE/FALSE to overwrite the present json
#' @param return_table TRUE/FALSE to return the data.table output
#' @param make_dir TRUE/FALSE make the directory for the patient sample if it does not exists
#' @return data.table or NULL
#' @export
#' @author Stanley Clarke, Tanubrata Dey, Joel Rosiene

meta_data_json = function(
    pair,
    out_file,
    genome = "hg19",
    coverage = NULL,
    jabba_gg = NULL,
    strelka2_vcf = NULL,
    sage_vcf = NULL,
    svaba_somatic_vcf = NULL,
    tumor_type = NULL,
    disease = NULL,
    primary_site = NULL,
    inferred_sex = NULL,
    karyograph = NULL,
    indel_sigprofiler = NULL,
    signatures_pair_name = NULL, # if different from pair
    sbs_sigprofiler = NULL,
    sbs_deconstructSigs = NULL,
    seqnames_loh = c(1:22),
    seqnames_genome_width = c(1:22,"X","Y"),
    write_json = TRUE,
    overwrite = FALSE,
    return_table = FALSE,
    make_dir = FALSE
) {
    if(!overwrite && write_json == TRUE) {
        if(file.exists(out_file)) {
            print(paste0('Output already exists! - skipping sample ',pair))
            return(NA)
        }
    }
    ## check if directory exists
    ## get folder
    split_file_path = strsplit(out_file, "/")[[1]]
    folder_path = paste0(split_file_path[1:(length(split_file_path)-1)], collapse = "/")
    if(!make_dir) {
        if(!file.exists(folder_path)) {
            print(paste0('Folder does not exist; skipping sample ', pair,". Use make_dir = TRUE to make directory"))
            return(NA)
        }
    }
    if(make_dir) {
        if(!file.exists(folder_path)) {
            cmd = paste0("mkdir -p ", folder_path)
            print(paste0('Making directory ', folder_path))
            system(cmd)
        }
    }
    ## meta.dt = data.table(pair = pair, tumor_type = tumor_type, tumor_type = tumor_type, disease = disease, primary_site = primary_site, inferred_sex = inferred_sex)

    meta.dt = data.table(pair = pair)
    if(!is.null(tumor_type)) {
        meta.dt[, tumor_type := tumor_type]
    }
    if(!is.null(disease)) {
        meta.dt[, disease := disease]
    }
    if(!is.null(primary_site)) {
        meta.dt[, primary_site := primary_site]
    }
    if(!is.null(inferred_sex)) {
        meta.dt[, inferred_sex := inferred_sex]
    }
    
    ##get derivate log ratio spread
    if(!is.null(coverage)) {
        meta.dt$dlrs = dlrs(readRDS(coverage)$foreground)
    }
    ##Load this case's counts
    ## meta.dt$snv_count = length(read_vcf(vcf))
    if(!is.null(strelka2_vcf)) {
        snv.counts.dt = strelka2counts(strelka2_vcf, seqnames_genome_width = seqnames_genome_width)
        meta.dt$snv_count = snv.counts.dt[category == "snv_count",]$counts
        meta.dt$snv_count_normal_vaf_greater0 = snv.counts.dt[category == "snv_count_normal_vaf_greater0",]$counts
    }
    if(is.null(sage_vcf) || sage_vcf == "") {
        warning("SAGE VCF not found as input, will only consider Strelka2 downstream...")
    } else {
        print("Found SAGE vcf, will use SAGE counts in meta file over Strelka2...")
        sage.snv.counts.dt = sage_count(sage_vcf, genome=genome)
        meta.dt$snv_count = sage.snv.counts.dt[category == "snv_count",]$counts
        meta.dt$snv_count_normal_vaf_greater0 = sage.snv.counts.dt[category == "snv_count_normal_vaf_greater0",]$counts
    }
    ## vcf.gr = read_vcf(vcf)
    ## vcf.gr$ALT = NULL # string set slows it down a lot - don't need it here
    ## meta.dt$snv_count = length(gr.nochr(vcf.gr) %Q% (seqnames %in% seqnames_genome_width))
    ## Count svs, want to count junctions as well as svs
    # gg = readRDS(jabba_gg)
    ## cmd = paste0("module unload java && module load java; module load gatk; gatk CountVariants --QUIET true --verbosity ERROR"," -V ",svaba_somatic_vcf)
    ## meta.dt$sv_count = system(paste(cmd, "2>/dev/null"), intern = TRUE)[2] %>% as.integer() #run the command without printing the java command
    if(!is.null(jabba_gg)) {
        ## count just junctions plus loose divided by 2, for sv counts for now
        gg = readRDS(jabba_gg)
        ## meta.dt$junction_count = nrow(gg$junctions$dt[type != "REF",])
        meta.dt$junction_count = nrow(gg$junctions$dt[type != "REF",])
        meta.dt$loose_count = nrow(as.data.table(gg$loose)[terminal == FALSE,])
        meta.dt[,sv_count := (junction_count + (loose_count / 2))]
                                        #get loh
        nodes.dt = gg$nodes$dt
        nodes.dt[, seqnames := gsub("chr","",seqnames)] #strip chr
        nodes.dt = gg$nodes$dt[seqnames %in% seqnames_loh]
        totalseglen = nodes.dt$width %>% sum()

        if('cn.low' %in% names(nodes.dt)) {
            LOHsegs = nodes.dt[cn.low==0,] %>% .[cn.high >0] %>% .$width %>% sum()
            ## LOH
            LOH_frc = LOHsegs/totalseglen
            meta.dt[,loh_fraction := LOH_frc]
            meta.dt[,loh_seglen := LOHsegs]
            meta.dt[,loh_total_genome := totalseglen]
        } else {
            meta.dt$loh_fraction = 'Not Allelic Jabba'
        }
        ##add purity and ploidy
        meta.dt$purity = gg$meta$purity
        meta.dt$ploidy = gg$meta$ploidy
        ##add the total seqlengths by using the seqlengths in the jabba object
        nodes.gr = gg$nodes$gr
        seqlengths.dt =suppressWarnings(as.data.table(seqinfo(nodes.gr), keep.rownames = "seqnames")) #had to supress, says other arguments ignored
        seqlengths.dt[, seqnames := gsub("chr","",seqnames)] #strip chr
        seqlengths.dt = seqlengths.dt[seqnames %in% seqnames_genome_width,]
        meta.dt$total_genome_length = sum(seqlengths.dt$seqlengths)

    }
    ## Load beta/gamma for karyograph
    if(!is.null(karyograph)) {
        kag = readRDS(karyograph)
        meta.dt$beta = kag$beta
        meta.dt$gamma = kag$gamma
    }
    ##add tmb
    if(("snv_count" %in% names(meta.dt)) & ("total_genome_length" %in% names(meta.dt))) {
        meta.dt[,tmb := (snv_count / (as.numeric(meta.dt$total_genome_length) / 1e6))]
        meta.dt[,tmb := round(tmb, digits = 3)]
    }

    if (!is.null(signatures_pair_name)) {
        sig_sample_name = signatures_pair_name
    } else {
        sig_sample_name = pair
    }
    ## add signatures that are present
    if(!is.null(sbs_deconstructSigs)) {
        signatures = sbs_deconstructSigs2meta(sbs_file = sbs_deconstructSigs, sample = sig_sample_name)
        ## meta.dt$signatures = list(as.list(signatures)) # Changed default to sigprofiler
        meta.dt$deconstructsigs_sbs_fraction = list(as.list(signatures))
    }
    if(!is.null(indel_sigprofiler)) {
        ## browser()
        deletionInsertion = indels_sigprofiler2meta(indel_file = indel_sigprofiler, sample = sig_sample_name)
        meta.dt$deletionInsertion = list(as.list(deletionInsertion[["indel_fraction"]]))
        meta.dt$sigprofiler_indel_fraction = list(as.list(deletionInsertion[["indel_fraction"]]))
        meta.dt$sigprofiler_indel_count = list(as.list(deletionInsertion[["indel_count"]]))
    } else {
        meta.dt$deletionInsertion = list()
        meta.dt$sigprofiler_indel_fraction = list()
        meta.dt$sigprofiler_indel_count = list()
    }

    if(!is.null(sbs_sigprofiler)) {
        signatures = sbs_sigprofiler2meta(sbs_file = sbs_sigprofiler, sample = sig_sample_name)
        meta.dt$sigprofiler_sbs_fraction = list(as.list(signatures[["sbs_fraction"]]))
        meta.dt$sigprofiler_sbs_count = list(as.list(signatures[["sbs_count"]]))
        meta.dt$signatures = list(as.list(signatures[["sbs_fraction"]])) #Changed default to sigprofiler
    } else {
        meta.dt$sigprofiler_sbs_fraction = list()
        meta.dt$sigprofiler_sbs_count = list()
        meta.dt$signatures = list()
    }
    ## end add signatures
    if(write_json) {
        ##write the json
        message(paste0("Writing json to ",out_file))
        write_json(meta.dt,out_file,pretty = TRUE, auto_unbox=TRUE)
        if(return_table) {
            return(meta.dt)
        }
        
    } else {
        return(meta.dt)
    }
}


#' @name create_distributions
#' @title create_distributions
#' @description
#'
#' function to create the meta data summary for samples in a case reports instance
#' 
#' @param case_reports_data_folder folder with all case report data by sample
#' @param common_folder path to a folder to write all 7 jsons
#' @param filter_pateints list of samples to filter on to create the distributions
#' @return NULL
#' @export
#' @author Stanley Clarke, Tanubrata Dey, Joel Rosiene

create_distributions = function(
    case_reports_data_folder,
    common_folder,
    filter_patients = NULL,
    write_jsons = TRUE,
    make_sub_folders = TRUE,
    cores = 1
) {
    case_reports_data_folder = paste0(case_reports_data_folder,"/")  ## just add a slash in case not added
    common_folder = paste0(common_folder,"/")  ## just add a slash in case not added
    if(write_jsons) {
        if(!file.exists(common_folder)) {
            stop("common_folder does not exist. Make the directory first")
        }
        ## folder_paths = paste0(common_folder,c("signatures","signatures/sbs","signatures/sbs_deconstructsigs","signatures/insertionDeletion","signatures/insertionDeletion_sigprofilerassignment/","signatures/insertionDeletion_counts_sigprofilerassignment/", "signatures/sbs_counts_deconstructsigs", "signatures/sbs_deconstructsigs/"))
        folder_paths = paste0(common_folder,c("signatures/sbs/", "signatures/deconstructsigs_sbs_fraction/", "signatures/insertionDeletion/", "signatures/sigprofiler_indel_fraction/", "signatures/sigprofiler_indel_count/", "signatures/sigprofiler_sbs_count/", "signatures/sigprofiler_sbs_fraction/"))
        ## make the subfolders if they do not exist
        if(make_sub_folders) {
            if(!all(file.exists(folder_paths))) {
                empty.lst = mclapply(folder_paths, function(folder_path) {
                    cmd = paste0("mkdir -p ", folder_path)
                    print(paste0('Making directory ', folder_path))
                    system(cmd)
                    return(NULL)
                }, mc.cores = cores)
            }
        }
    }
    ## get files from case reports folder and subset if filter_pateints
    files.lst = list.files(case_reports_data_folder)
    files.lst = grep("data",files.lst,invert=TRUE, value = TRUE)
    meta.dt = data.table(meta_json = paste0(case_reports_data_folder,files.lst,"/metadata.json"), patient_id = files.lst)
    meta.dt = meta.dt[file.exists(meta_json),]
    if(!is.null(filter_patients)) {
        meta.dt = meta.dt[patient_id %in% filter_patients,]
    }
    
    jsons.lst = mclapply(1:nrow(meta.dt), function(x) {
        meta.sub.dt = meta.dt[x,]
        read_meta_data_json(meta_json = meta.sub.dt$meta_json, patient_id = meta.sub.dt$patient_id)
    },mc.cores = cores)
    jsons.dt = rbindlist(jsons.lst, fill = TRUE)
    if("snv_count" %in% names(jsons.dt)) {
        ##snv distribution json
        snv.dt = jsons.dt[,.(pair, snv_count,tumor_type)] %>% setnames(.,c("pair","value","tumor_type"))
    } else {
        snv.dt = NULL
    }
    if("sv_count" %in% names(jsons.dt)) {
        ##sv distribution json
        sv.dt = jsons.dt[,.(pair, sv_count, tumor_type)] %>% setnames(.,c("pair","value","tumor_type"))
        sv.dt[,id := 1:.N]
        sv.dt = sv.dt[,.(id,pair,value, tumor_type)]
    } else {
        sv.dt = NULL
    }
    if(all(c("loh_fraction","loh_seglen","loh_total_genome") %in% names(jsons.dt))) {
        ##loh
        loh.dt = jsons.dt[,.(pair, tumor_type,loh_fraction,loh_seglen,loh_total_genome)] %>% setnames(.,c("pair","tumor_type","value","LOH_seg_len","genome_width"))
    } else {
        loh.dt = NULL
    }
    
    if("ploidy" %in% names(jsons.dt)) {
        ##ploidy
        ploidy.dt = jsons.dt[,.(pair, tumor_type, ploidy, purity)] %>% setnames(.,c("pair","tumor_type","value","purity"))
    } else {
        ploidy.dt = NULL
    }
    if("purity" %in% names(jsons.dt)) {
        ##purity
        purity.dt = jsons.dt[,.(pair, tumor_type, ploidy, purity)] %>% setnames(.,c("pair","tumor_type","ploidy","value"))
    } else {
        purity.dt = NULL
    }
    if("dlrs" %in% names(jsons.dt)) {
        ##coverage variance
        cov_var.dt = jsons.dt[,.(pair, tumor_type, dlrs)] %>% setnames(.,c("pair","tumor_type_mod","value"))
    } else {
        cov_var.dt = NULL
    }
    if("tmb" %in% names(jsons.dt)) {
        ##tmb
        tmb.dt = jsons.dt[,.(pair, tmb, tumor_type)] %>% setnames(.,c("pair","value","tumor_type"))
    } else {
        tmb.dt = NULL
    }
########################################################################################################################################
    ## convert the signatures to data.tables that can be outputted for the distributions
    sigs.lst = convert_signature_meta_json(jsons.dt = jsons.dt, cores = cores)
    if(write_jsons == TRUE) {
        ##writing jsons
        message(paste0("writing jsons to ",common_folder))
        write_json(snv.dt,paste0(common_folder,"/snvCount.json"),pretty = TRUE)
        write_json(sv.dt,paste0(common_folder,"/svCount.json"),pretty = TRUE)
        write_json(loh.dt,paste0(common_folder,"/lohFraction.json"),pretty = TRUE)
        write_json(ploidy.dt,paste0(common_folder,"/ploidy.json"),pretty = TRUE)
        write_json(purity.dt,paste0(common_folder,"/purity.json"),pretty = TRUE)
        write_json(cov_var.dt,paste0(common_folder,"/coverageVariance.json"),pretty = TRUE)
        write_json(tmb.dt,paste0(common_folder,"/tmb.json"),pretty = TRUE)
        ## write distribution files for all distributions
        write_signature_jsons(signatures_list = sigs.lst, common_folder = common_folder, cores = cores)
    } else {
        ## start of returning all the distributions if write_jsons != TRUE
        ## return the different signatures if they exist on returning
        if("deconstruct_sigs.dt" %in% names(sigs.lst)) {
            deconstruct_sigs.dt = sigs.lst[["deconstruct_sigs.dt"]]
        } else {
            deconstruct_sigs.dt = NULL
        }
        
        if("sigprofilerassignment_indels.dt" %in% names(sigs.lst)) {
            sigprofilerassignment_indels.dt = sigs.lst[["sigprofilerassignment_indels.dt"]]
        } else {
            sigprofilerassignment_indels.dt = NULL
        }
        
        if("sigprofilerassignment_indels_counts.dt" %in% names(sigs.lst)) {
            sigprofilerassignment_indels_counts.dt = sigs.lst[["sigprofilerassignment_indels_counts.dt"]]
        } else {
            sigprofilerassignment_indels_counts.dt = NULL
        }
        
        if("sigprofilerassignment_sbs_counts.dt" %in% names(sigs.lst)) {
            sigprofilerassignment_sbs_counts.dt = sigs.lst[["sigprofilerassignment_sbs_counts.dt"]]
        } else {
            sigprofilerassignment_sbs_counts.dt = NULL
        }
        
        if("sigprofilerassignment_sbs.dt" %in% names(sigs.lst)) {
            sigprofilerassignment_sbs.dt = sigs.lst[["sigprofilerassignment_sbs.dt"]]
        } else {
            sigprofilerassignment_sbs.dt = NULL
        }
        ## return(list(snv.dt,sv.dt,loh.dt,ploidy.dt,purity.dt,cov_var.dt,tmb.dt))
        json.lst = list(snv.dt,sv.dt,loh.dt,ploidy.dt,purity.dt,cov_var.dt,tmb.dt,deconstruct_sigs.dt, sigprofilerassignment_indels.dt,sigprofilerassignment_indels_counts.dt,sigprofilerassignment_sbs_counts.dt,sigprofilerassignment_sbs.dt)
        ## names(json.lst) = c("snvCount", "svCount","lohFraction", "ploidy", "purity", "coverageVariance", "tmb", "deconstruct_sigs","sigprofilerassignment_indels","sigprofilerassignment_indels_counts.dt", "sigprofilerassignment_sbs_counts.dt", "sigprofilerassignment_sbs.dt")
        names(json.lst) = c("snvCount", "svCount","lohFraction", "ploidy", "purity", "coverageVariance", "tmb", "sbs","sigprofiler_indel_fraction","sigprofiler_indel_count", "sigprofiler_sbs_count", "sigprofiler_sbs_fraction")
        return(json.lst)
    }
}


#' @name load_distributions
#' @title load_distributions
#' @description
#'
#' function to read in distributions files, same format returned as create_distributions with write_jsons = FALSE
#' 
#' @param common_folder path to a folder to write all 7 jsons
#' @param filter_pateints list of samples to filter on to read in the distributions
#' @return NULL
#' @export
#' @author Stanley Clarke
load_distributions = function(common_folder, filter_patients = NULL) {
    files.lst = paste0(common_folder, c("coverageVariance.json", "lohFraction.json", "ploidy.json", "purity.json", "snvCount.json", "svCount.json", "tmb.json"))
    files.dt = data.table(name = c("coverageVariance", "lohFraction", "ploidy", "purity", "snvCount", "svCount", "tmb"), file = files.lst)
    json.lst = lapply(setNames(nm = files.dt$name), function(name1) {
        file1 = files.dt[name == name1,]$file
        if(!is.null(filter_patients)) {
            json.dt = as.data.table(fromJSON(file1))
            json.sub.dt = json.dt[pair %in% filter_patients,]
            return(json.sub.dt)
        }
        return(as.data.table(fromJSON(file1)))
    })
    return(json.lst)
}


#' @name bw_temp
#' @title bw_temp
#' @description
#'
#' function to create data.table for bigwig files for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x path to a granges rds or a granges object
#' @param ref reference to use for pgvdb
#' @param chart_type defaultChartType for pgvdb, default is area, can also be scatterplot
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param type bigwig, should not change for this plot type
#' @param field field to plot as the y value, default is foreground
#' @param overwrite TRUE/FALSE to overwrite an existing bw
#' @return NULL
#' @export
#' @author Stanley Clarke

bw_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    chart_type = "area",
    visible = TRUE,
    title = NA,
    type = "bigwig",
    field = "foreground",
    overwrite = FALSE
) {
    dt1 = data.table(patient.id = patient_id,
                     visible = visible,
                     x = x,
                     type = type,
                     field = field,
                     ref = ref,
                     title = title,
                     order = order,
                     defaultChartType = chart_type,
                     overwrite = overwrite
                     )
    return(dt1)
}


#' @name arrow_temp
#' @title arrow_temp
#' @description
#'
#' function to create data.table for arrow files for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x path to a granges rds or a granges object
#' @param ref reference to use for pgvdb
#' @param chart_type defaultChartType for pgvdb, default is scatterplot, can also be area
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param type scatterplot, should not change for this plot type
#' @param field field to plot as the y value, default is foreground
#' @param overwrite TRUE/FALSE to overwrite an existing arrow
#' @return NULL
#' @export
#' @author Stanley Clarke

arrow_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    source = "coverage.arrow",
    chart_type = "scatterplot",
    visible = TRUE,
    title = NA,
    type = "scatterplot",
    field = "foreground",
    overwrite = FALSE
) {
    dt1 = data.table(patient.id = patient_id,
                     visible = visible,
                     x = x,
                     type = type,
                     field = field,
                     ref = ref,
                     source = source,
                     title = title,
                     order = order,
                     defaultChartType = chart_type,
                     overwrite = overwrite
                     )
    return(dt1)
}

#' @name genome_temp
#' @title genome_temp
#' @description
#'
#' function to create data.table for genome graphs for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x path to a JaBbA ggraph object or object itself as a list
#' @param ref reference to use for pgvdb
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param max.cn override max cn of 100
#' @param type genome, can be changed to allelic to render allelic graphs
#' @param annotation default is list of SVs, make null if no annotations present in object
#' @param overwrite TRUE/FALSE to overwrite an existing genome json
#' @return NULL
#' @export
#' @author Stanley Clarke

genome_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    source = "genome.json",
    type = "genome",
    visible = TRUE,
    title = NA,
    max.cn = NULL,
    annotation = list(c('bfb','chromoplexy','chromothripsis','del','dm','cpxdm','dup','pyrgo','rigma','simple','tic','tyfonas')),
    overwrite = FALSE
) {
                                        #use type = allelic to make a color a genome graph
    dt1 = data.table(
        patient.id = patient_id,
        type = type,
        visible = visible,
        title = title,
        x = x,
        ref = ref,
        source = source,
        max.cn = max.cn,
        order = order,
        annotation = annotation,
        overwrite = overwrite
    )
    return(dt1)
}

#' @name walks_temp
#' @title walks_temp
#' @description
#'
#' function to create data.table for walks for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x walks object as a list
#' @param ref reference to use for pgvdb
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param type walk, do not change for this plot type
#' @param annotation default is list of SVs, make null if no annotations present in object
#' @param overwrite TRUE/FALSE to overwrite an existing genome json
#' @param tag optional argument, can be binset to override y spacing in pgv
#' @return NULL
#' @export
#' @author Stanley Clarke

walks_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    source = "walks.json",
    type = "walk",
    visible = TRUE,
    title = NA,
    tag = NA,
    overwrite = FALSE
) {
    dt1 = data.table(
        patient.id = patient_id,
        visible = visible,
        x = x,
        type = type,
        order = order,
        ref = ref,
        source = source,
        title = title,
        overwrite = overwrite
    )
    return(dt1)
}

#' @name mutations_temp
#' @title mutations_temp
#' @description
#'
#' function to create data.table for mutations for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x mutations object as a list
#' @param ref reference to use for pgvdb
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param type walk, do not change for this plot type
#' @param annotation default is list of SVs, make null if no annotations present in object
#' @param overwrite TRUE/FALSE to overwrite an existing genome json
#' @param tag optional argument, can be binset to override y spacing in pgv
#' @return NULL
#' @export
#' @author Stanley Clarke

mutations_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    source = "mutations.json",
    field,
    type = "mutations",
    visible = TRUE,
    title = NA,
    tag = NA,
    overwrite = FALSE
) {
    dt1 = data.table(
        patient.id = patient_id,
        visible = visible,
        type = type,
        x = x,
        field = field,
        order = order,
        ref = ref,
        source = source,
        title = title,
        overwrite = overwrite
    )
    return(dt1)
}

#' @name ppfit_temp
#' @title ppfit_temp
#' @description
#'
#' function to create data.table for ppfit for pgvdb
#' 
#' @param patient_id patient.id to be added to pgvdb
#' @param order optional entry if you order plots with a column order
#' @param x jabba.rds
#' @param ref reference to use for pgvdb
#' @param visible TRUE/FALSE whether the plot is hidden or showing in pgv
#' @param title title of the plot in pgvdb
#' @param type ppfit, do not change for this plot type
#' @param annotation default is NULL, currently won't work for ppfit
#' @param overwrite TRUE/FALSE to overwrite an existing genome json
#' @param tag optional argument, can be binset to override y spacing in pgv
#' @return NULL
#' @export
#' @author Stanley Clarke

ppfit_temp = function(
    patient_id = NA,
    order = NA,
    x = list(NA),
    ref = NA,
    source = "ppfit.json",
    type = "ppfit",     #use type = allelic to make a colored genome graph
    visible = TRUE,
    title = NA,
    annotation = NULL,
    overwrite = FALSE
) {
    
    dt1 = data.table(
        patient.id = patient_id,
        type = type,
        visible = visible,
        title = title,
        x = x,
        ref = ref,
        source = source,
        order = order,
        annotation = annotation,
        overwrite = overwrite
    )
    return(dt1)
}

#' @name create_ppfit_json
#' @title create_ppfit_json
#' @description
#'
#' function to create segmentation plots in case reports
#' 
#' @param balanced_gg the balanced_gg ggraph or the path to it
#' @param cov path to associated coverage, if null, will try to pull path from pairs table
#' @param path_obj path to flow directory, if null, must supply coverage path
#' @param settings_json path to settings.json (from PGV)
#' @param ref reference name
#' @param max_na max.na used with JaBbA
#' @param out_file location to write json
#' @param write_json TRUE/FALSE whether to write the json
#' @param return_table TRUE/FALSE whether to return the data
#' @param overwrite TRUE/FALSE whether to overwrite existing file
#' @param cores cores for JaBbA:::segstats
#' @return NULL or segstats table
#' @export
#' @author Stanley Clarke, Tanubrata Dey

create_ppfit_json = function(
    balanced_gg,
    cov_path = NULL,
    path_obj = NULL,
    settings_json,
    ref = NULL,
    max_na = NULL,
    out_file = NULL,
    write_json = TRUE,
    overwrite = FALSE,
    return_table = FALSE,
    cores = 1
) {

    if(!is.null(out_file)) {
        if(!overwrite) {
            if(file.exists(out_file)) {
                print('Output already exists! - skipping sample')
                return(NA)
            }
        }
    }

    #'drcln_cov = readRDS(thisp$decomposed_cov[i])
    ##make this work with complex where the cov file was not an input and with jabba_gg
    ## x = path_obj %>% sniff %>% inputs %>% select(CovFile, maxna) #get coverage that was used for the jabba run
    if (!is.null(cov_path)) {
        cov = readRDS(cov_path)
    } else if (!is.null(path_obj)) {
        inputs.dt = path_obj %>% sniff %>% inputs
        if(!any(grepl("CovFile", names(inputs.dt))) & any(grepl("jabba", names(inputs.dt)))) {
            x = inputs.dt$jabba %>% sniff %>% inputs %>% .[,.(CovFile,maxna)]
        } else if (!any(grepl("CovFile", names(inputs.dt))) & any(grepl("jab", names(inputs.dt)))) {
            x = inputs.dt$jab %>% sniff %>% inputs %>% .[,.(CovFile,maxna)]
        } else {
            x = path_obj %>% sniff %>% inputs %>% .[,.(CovFile,maxna)]
        }
        cov = readRDS(x$CovFile)
        max_na = as.numeric(x$maxna)
    } else {
        stop("Must supply either coverage path or flow directory path object")
    }

    if (is.null(ref)) {
        warning("ref was not passed, setting to default: hg19")
        ref = "hg19"
    }

    if (is.null(max_na)) {
        warning("max_na was not passed/found, setting to default: 0.9")
        max_na = 0.9
    }

    if ("ratio" %in% names(mcols(cov))) {
        message(paste0("Raw 'cov.rds' was used as input for JaBbA ",path_obj, ", will consider field as 'ratio''\n"))
        field = "ratio"
    } else if ("foreground" %in% names(mcols(cov))) {
        message(paste0("Drycleaned 'drycleaned.cov.rds' was used as input for JaBbA ",path_obj, ", will consider field as 'foreground''\n"))
        field = "foreground"
    }
    if(!(field %in% c("ratio","foreground"))) {
        stop("Cov file is not clear. Ratio nor foreground in the the columns of the coverage file")
    }
    ##need to replace NaN with NA or JaBbA:::segstats breaks
    if(field == "ratio") {
        cov$ratio = gsub("NaN",NA,cov$ratio) %>% as.numeric
    } else if (field == "foreground") {
        cov$foreground = gsub("NaN",NA,cov$foreground) %>% as.numeric
    }
    if (is(balanced_gg, "gGraph")) {
        balanced_gg_gr = balanced_gg$nodes$gr
    } else if (is(balanced_gg, "character")) {
        balanced_gg_gr = readRDS(balanced_gg)$nodes$gr
    }
    
    segstats = JaBbA:::segstats(balanced_gg_gr,
                                cov,
                                field = field,
                                prior_weight = 1,
                                max.chunk = 1e8,
                                ## subsample = subsample,
                                mc.cores = cores,
                                verbose = FALSE,
                                max.na = max_na,
                                lp = FALSE)
    segstats.dt = gr2dt(segstats)
    names(segstats.dt) = gsub("\\.","_",names(segstats.dt))
    if(write_json) {
        message("Cleaning up for writing ppfit to json")
        seq_lengths <- gGnome::parse.js.seqlengths(
                                 settings_json,
                                 js.type = "PGV",
                                 ref = ref
                               )
        segstats.gr = GRanges(segstats.dt, seqlengths = seq_lengths) %>% trim
        ggraph = readRDS(balanced_gg)
        ggraph2 = gG(nodes = segstats.gr, edges = ggraph$edges$dt)
        fields.keep = names(segstats.dt) %>% grep("cn",.,invert = TRUE, value = TRUE)
        ggraph2$set(y.field = "cn")
        ## check for overlap in sequence names
        ggraph.reduced <- ggraph2[seqnames %in% names(seq_lengths)]
        if (length(ggraph.reduced) == 0) {
          stop(sprintf(
            'There is no overlap between the sequence names in the reference
                    used by PGV and the sequences in your gGraph. Here is an
                    example sequence from your gGraph: "%s". And here is an
                    example sequence from the reference used by gGnome.js: "%s"',
            seqlevels(ggraph.reduced$nodes$gr)[1], names(seq_lengths)[1]
          ))
        }
        message(paste0("Writing json to ",out_file))
        gGnome::refresh(ggraph.reduced)$json(
            filename = out_file,
            verbose = TRUE,
            maxcn = 500,
            nfields = fields.keep,
            save = TRUE
        )
    }
    if(return_table) {
        return(segstats.dt)
    }
}


#' @name cov_abs
#' @title cov_abs
#' @description
#'
#' function to run rel2abs on coverage taking either a ggraph or purity & ploidy
#' 
#' @param dryclean_cov dryclean coverage
#' @param jabba_gg optional jabba ggraph. If null, needs purity or ploidy
#' @param purity optional purity value. If null needs ggraph
#' @param ploidy optional ploidy value. If null needs ggraph
#' @param field column in granges to convert with rel2abs
#' @param new_col new column to add to add for the converted rel2abs
#' @return NULL or segstats table
#' @export
#' @author Stanley Clarke
cov2abs = function(
    dryclean_cov,
    jabba_gg = NULL,
    purity = NULL,
    ploidy = NULL,
    field = "foreground",
    new_col = "foregroundabs"
) {
    cov_gr = readRDS(dryclean_cov)
    if(!is.null(jabba_gg)) {
        gg = readRDS(jabba_gg)
        purity = gg$meta$purity
        ploidy = gg$meta$ploidy
    }
    if(!is.null(purity) && !is.null(ploidy)) {
        purity = purity
        ploidy = ploidy
    }
    mcols(cov_gr)[new_col] = rel2abs(gr = cov_gr,
                                     purity = purity,
                                     ploidy = ploidy,
                                     field = field
                                     )
    return(cov_gr)
}

#' @name cov2arrow_pgv
#' @title cov2arrow_pgv
#' @description
#'
#' function to create arrow with rel2abs from coverage file. Can take a ggraph or specified purity and ploidy to calculate rel2abs
#' 
#' @param patient.id patient name to add to pgv
#' @param dryclean_cov dryclean coverage
#' @param ref reference for pgv
#' @param field column in granges to convert with rel2abs
#' @param jabba_gg optional jabba ggraph. If null, needs purity or ploidy
#' @param purity optional purity value. If null needs ggraph
#' @param ploidy optional ploidy value. If null needs ggraph
#' @param title title for ggraph
#' @param mask optional mask to use after rebinning
#' @param title title for ggraph
#' @param ref reference to use for pgvdb
#' @param title optional title for plot for pgvdb
#' @param seq.fix optional seqlengths vector to fix granges seqlengths
#' @param chart_type default chart type for plot in pgvdb. scatterplot or area
#' @param visible whether the plot is visible in pgv
#' @param field column to do rel2abs on
#' @param new_col new column after rel2abs
#' @param overwrite whether to overwrite the current bigwig
#' @param order optional order if using a column order in your pgvdb object to sort
#' @param binsize size to rebin coverages, default 1e4
#' @return NULL or segstats table
#' @export
#' @author Stanley Clarke
cov2arrow_pgv = function(
    patient.id,
    dryclean_cov,
    jabba_gg = NULL,
    purity = NULL,
    ploidy = NULL,
    mask = NULL,
    ref,
    title = NA,
    seq.fix = NULL,
    chart_type = "scatterplot",
    visible = TRUE,
    field = "foreground",
    new_col = "foregroundabs",
    overwrite = FALSE,
    order = NA,
    binsize = 1e4
) {
    if(!is.null(jabba_gg)) {
        cov_gr = cov2abs(dryclean_cov, jabba_gg, field = field, new_col = new_col)
    } else if(!is.null(purity) && !is.null(ploidy)) {
        cov_gr = cov2abs(dryclean_cov, purity = purity, ploidy = ploidy)
    } else {
        cov_gr = readRDS(dryclean_cov)
    }
    if(!is.null(mask)) {
        cov_gr = gr.val(cov_gr,mask, "mask")
        cov_gr = cov_gr %Q% (is.na(mask))
        cov_gr$mask = NULL
    }
    cov_gr2 = rebin(cov_gr, binsize, field = field)
    if(length(cov_gr2$foregroundabs[cov_gr2$foregroundabs < 0]) > 0) {
        cov_gr2$foregroundabs[cov_gr2$foregroundabs < 0] = 0
    }    
    add.dt = arrow_temp(patient_id = patient.id, ref = ref, field = field, x = list(cov_gr2), title = title, overwrite = overwrite, order = NA, chart_type = chart_type, visible = visible)
    return(add.dt)
}

#' @name cov2bw_pgv
#' @title cov2bw_pgv
#' @description
#'
#' function to create bigwig with rel2abs from coverage file. Can take a ggraph or specified purity and ploidy to calculate rel2abs
#' 
#' @param patient.id patient name to add to pgv
#' @param dryclean_cov dryclean coverage
#' @param ref reference for pgv
#' @param field column in granges to convert with rel2abs
#' @param jabba_gg optional jabba ggraph. If null, needs purity or ploidy
#' @param purity optional purity value. If null needs ggraph
#' @param ploidy optional ploidy value. If null needs ggraph
#' @param mask mask to remove coverages from
#' @param title title for ggraph
#' @param ref reference to use for pgvdb
#' @param title optional title for plot for pgvdb
#' @param seq.fix optional seqlengths vector to fix granges seqlengths
#' @param chart_type default chart type for plot in pgvdb. scatterplot or area
#' @param visible whether the plot is visible in pgv
#' @param field column to do rel2abs on
#' @param new_col new column after rel2abs
#' @param overwrite whether to overwrite the current bigwig
#' @param order optional order if using a column order in your pgvdb object to sort
#' @param mask optional mask to use after rebinning
#' @return NULL or segstats table
#' @export
#' @author Stanley Clarke

## function to not rebin using higlass but mask
cov2bw_pgv = function(
    patient.id,
    dryclean_cov,
    jabba_gg = NULL,
    purity = NULL,
    ploidy = NULL,
    mask = NULL,
    ref,
    title = NA,
    seq.fix = NULL,
    chart_type = "scatterplot",
    visible = TRUE,
    field = "foreground",
    new_col = "foregroundabs",
    overwrite = FALSE,
    order = NA
) {
    if(!is.null(jabba_gg)) {
        cov_gr = cov2abs(dryclean_cov, jabba_gg, field = field, new_col = new_col)
    } else if(!is.null(purity) && !is.null(ploidy)) {
        cov_gr = cov2abs(dryclean_cov, purity = purity, ploidy = ploidy)
    } else {
        cov_gr = readRDS(dryclean_cov)
    }
    ## cov_gr = cov2abs(dryclean_cov, jabba_gg, field = field, new_col = new_col)
    if(!is.null(mask)) {
        cov_gr = gr.val(cov_gr,mask, "mask")
        cov_gr = cov_gr %Q% (is.na(mask))
        cov_gr$mask = NULL
    }
    if(length(cov_gr$foregroundabs[cov_gr$foregroundabs < 0]) > 0) {
        cov_gr$foregroundabs[cov_gr$foregroundabs < 0] = 0
    }
    if(!is.null(seq.fix)) {
        ## fix seqlengths to specified seqlengths
        cov_gr = GRanges(as.data.table(cov_gr),seqlengths = seq.fix) %>% trim()
    }
    add.dt = bw_temp(
        patient_id = patient.id,
        ref = ref,
        field = new_col,
        x = list(cov_gr),
        title = title,
        overwrite = overwrite,
        order = NA,
        chart_type = chart_type,
        visible = visible
    )
    return(add.dt)
}

#' @name indels_sigprofiler2meta
#' @title indels_sigprofiler2meta
#' @description
#' function to generate metadata indel signature list from sigprofiler output
#'
#' @param indel_file path to Assignment_Solution_Activities.txt, output of sigprofiler
#' @param sample sample or pair name-needed to subset to the correct sample
#' 
#' @return 
#' @export
#' @author Sukanya Panja, Stanley Clarke
indels_sigprofiler2meta = function(indel_file, sample) {
    ## indel signatures first
    indel_sig = fread(indel_file)
    indel_sig[, pair := gsub("_somatic","",Samples)]
    indel_sig[,Samples := NULL]
    indel_sig = indel_sig[pair == sample,]
    indel_sig_avg = copy(indel_sig)
    indel_sig_avg[, pair := NULL]
    row_sum = indel_sig_avg %>% rowSums()
    indels.dt = melt.data.table(indel_sig_avg, measure.vars = names(indel_sig_avg)) %>% setnames(.,c("signature","value"))
    indels.dt[, avg_value := value / row_sum]
    indels.vect = indels.dt$avg_value
    names(indels.vect) = indels.dt$signature
    indels_counts.vect = indels.dt$value
    names(indels_counts.vect) = indels.dt$signature
    indels.lst = list(indels.vect,indels_counts.vect)
    names(indels.lst) = c("indel_fraction","indel_count")
    return(indels.lst)
}


#' @name sbs_deconstructSigs2meta
#' @title sbs_deconstructSigs2meta
#' @description
#' generates list of SBS signatures from the output of deconstruct sigs to add to metadata
#'
#' @param sbs_file path to rds outpyut from deconstructSigs
#' @param sample sample or pair name-needed to subset to the correct sample
#' 
#' @return 
#' @export
#' @author Sukanya Panja, Stanley Clarke
sbs_deconstructSigs2meta = function(sbs_file, sample) {
    sig_file = readRDS(sbs_file)
    weights = as.data.table(sig_file$weights)
    weights = t(weights)
    sigs.dt = as.data.table(weights, keep.rownames = "Signature") %>% setnames(.,c("Signature","weights"))
    sigs.dt[, Signature := gsub("Signature.","SBS", Signature)]
    sigs.vect = sigs.dt$weights
    names(sigs.vect) = sigs.dt$Signature
    ##pair.vect = sample
    ##names(pair.vect) = "pair"
    ##sigs.vect = c(pair.vect,sigs.vect)
    ## signatures = list(signatures = as.list(sigs.vect))
    return(sigs.vect)
}


#' @name sbs_sigprofiler2meta
#' @title sbs_sigprofiler2meta
#' @description
#' generates list of SBS signature counts and percentages from the output of deconstruct sigs to add to metadata
#'
#' @param sbs_file path to Assignment_Solution_Activities.txt, output of sigprofiler
#' @param sample sample or pair name-needed to subset to the correct sample
#' 
#' @return list of length 2, first being the signatures as a fraction and second being signatures as counts
#' @export
#' @author Stanley Clarke
sbs_sigprofiler2meta = function(sbs_file, sample) {
    sig.dt = fread(sbs_file)
    sig.dt[, pair := gsub("_somatic","",Samples)]
    sig.dt = sig.dt[pair == sample,]
    sig.dt[,Samples := NULL]
    sig.dt_avg = copy(sig.dt)
    sig.dt_avg[, pair := NULL]
    row_sum = sig.dt_avg %>% rowSums()
    sigs.dt = melt.data.table(sig.dt_avg, measure.vars = names(sig.dt_avg)) %>% setnames(.,c("signature","value"))
    sigs.dt[, avg_value := value / row_sum]
    sigs.vect = sigs.dt$avg_value
    names(sigs.vect) = sigs.dt$signature
    sigs_counts.vect = sigs.dt$value
    names(sigs_counts.vect) = sigs.dt$signature
    sigs.lst = list(sigs.vect,sigs_counts.vect)
    names(sigs.lst) = c("sbs_fraction","sbs_count")
    return(sigs.lst)
}


#' @name read_meta_data_json
#' @title read_meta_data_json
#' @description
#' Reads in meta data jsons and gets signatures that are lists into the correct list format in the data.table. Used in create_distributions
#'
#' @param meta_json path to metadata.json for case reports
#' @param patient_id sample name for metadata_json
#' 
#' @return data.table of the metadata.json for each sample
#' @export
#' @author Stanley Clarke
read_meta_data_json = function(meta_json, patient_id) {
    json.dt = as.data.table(jsonlite::read_json(meta_json,simplifyVector = TRUE)) ## have to change from this to work with signatures
    keep_cols = names(json.dt) %>% grep("signatures|deletionInsertion|sigprofiler|deconstructsigs",., value = TRUE, invert = TRUE)
    json.dt = json.dt[,..keep_cols]
    json.lst = jsonlite::read_json(meta_json,simplifyVector = FALSE)
    if(!is.null(json.lst[[1]]$signatures)) {
        json.dt$signatures = list(json.lst[[1]]$signatures)
    }
    if(!is.null(json.lst[[1]]$deletionInsertion)) {
        json.dt$deletionInsertion = list(json.lst[[1]]$deletionInsertion)
    }
    if(!is.null(json.lst[[1]]$deconstructsigs_sbs_fraction)) {
        json.dt$deconstructsigs_sbs_fraction = list(json.lst[[1]]$deconstructsigs_sbs_fraction)
    }
    if(!is.null(json.lst[[1]]$sigprofiler_indel_fraction)) {
        json.dt$sigprofiler_indel_fraction = list(json.lst[[1]]$sigprofiler_indel_fraction)
    }
    if(!is.null(json.lst[[1]]$sigprofiler_indel_count)) {
        json.dt$sigprofiler_indel_count = list(json.lst[[1]]$sigprofiler_indel_count)
    }
    if(!is.null(json.lst[[1]]$sigprofiler_sbs_fraction)) {
        json.dt$sigprofiler_sbs_fraction = list(json.lst[[1]]$sigprofiler_sbs_fraction)
    }
    if(!is.null(json.lst[[1]]$sigprofiler_sbs_count)) {
        json.dt$sigprofiler_sbs_count = list(json.lst[[1]]$sigprofiler_sbs_count)
    }
    return(json.dt)
}

#' @name convert_signature_meta_json
#' @title convert_signature_meta_json
#' @description
#' converts signatures from the list objects in the meta data to data.tables to write jsons for distributions. Used in create_distributions
#'
#' @param jsons.dt json dt after using read_meta_data_json
#' @param cores cores for generating each signature
#' @return list object with all of the signature distribution data.tables
#' @export
#' @author Stanley Clarke
convert_signature_meta_json = function(jsons.dt, cores = 1) {
    ## signatures-sbs deconstruct sigs ## in column signatures but also in deconstructsigs_sbs_fraction
    if("signatures" %in% names(jsons.dt)) {
        jsons.dt2 = copy(jsons.dt)
        jsons.dt2[, length_signatures := sapply(signatures, function(x) length(unlist(x)))]
        jsons.dt2 = jsons.dt2[length_signatures != 0,]
        sigs.lst = mclapply(1:nrow(jsons.dt2), function(x) {
            jsons.sub.dt2 = jsons.dt2[x,]
            sigs.dt = jsons.sub.dt2$signatures[[1]] %>% as.data.table()
            sigs.dt[, pair := jsons.sub.dt2$pair]
            sigs.dt[, tumor_type := jsons.sub.dt2$tumor_type]
            return(sigs.dt)
        }, mc.cores = cores)
        deconstruct_sigs.dt = rbindlist(sigs.lst, fill = TRUE)
    }
    ## signatures-indels sigprofiler assignment## in column deletionInsertion and sigprofiler_indel_fraction
    if("deletionInsertion" %in% names(jsons.dt)) {
        jsons.dt2 = copy(jsons.dt)
        jsons.dt2[, length_signatures := sapply(deletionInsertion, function(x) length(unlist(x)))]
        jsons.dt2 = jsons.dt2[length_signatures != 0,]
        sigs.lst = mclapply(1:nrow(jsons.dt2), function(x) {
            jsons.sub.dt2 = jsons.dt2[x,]
            sigs.dt = jsons.sub.dt2$deletionInsertion[[1]] %>% as.data.table()
            sigs.dt[, pair := jsons.sub.dt2$pair]
            sigs.dt[, tumor_type := jsons.sub.dt2$tumor_type]
            return(sigs.dt)
        }, mc.cores = cores)
        sigprofilerassignment_indels.dt = rbindlist(sigs.lst, fill = TRUE)
    }
    ## signatures-indel counts sigprofiler assignment
    if("sigprofiler_indel_count" %in% names(jsons.dt)) {
        jsons.dt2 = copy(jsons.dt)
        jsons.dt2[, length_signatures := sapply(sigprofiler_indel_count, function(x) length(unlist(x)))]
        jsons.dt2 = jsons.dt2[length_signatures != 0,]
        sigs.lst = mclapply(1:nrow(jsons.dt2), function(x) {
            jsons.sub.dt2 = jsons.dt2[x,]
            sigs.dt = jsons.sub.dt2$sigprofiler_indel_count[[1]] %>% as.data.table()
            sigs.dt[, pair := jsons.sub.dt2$pair]
            sigs.dt[, tumor_type := jsons.sub.dt2$tumor_type]
            return(sigs.dt)
        }, mc.cores = cores)
        sigprofilerassignment_indels_counts.dt = rbindlist(sigs.lst, fill = TRUE)
    } else {
        sigprofilerassignment_indels_counts.dt = NULL
    }
    ## signatures-sigprofiler sbs fraction
    if("sigprofiler_sbs_fraction"  %in% names(jsons.dt)) {
        jsons.dt2 = copy(jsons.dt)
        jsons.dt2[, length_signatures := sapply(sigprofiler_sbs_fraction, function(x) length(unlist(x)))]
        jsons.dt2 = jsons.dt2[length_signatures != 0,]
        sigs.lst = mclapply(1:nrow(jsons.dt2), function(x) {
            jsons.sub.dt2 = jsons.dt2[x,]
            sigs.dt = jsons.sub.dt2$sigprofiler_sbs_fraction[[1]] %>% as.data.table()
            sigs.dt[, pair := jsons.sub.dt2$pair]
            sigs.dt[, tumor_type := jsons.sub.dt2$tumor_type]
            return(sigs.dt)
        }, mc.cores = cores)
        sigprofilerassignment_sbs.dt = rbindlist(sigs.lst, fill = TRUE)
    } else {
        sigprofilerassignment_sbs.dt = NULL
    }
    
    ## signatures-sigprofiler sbs count
    if("sigprofiler_sbs_count"  %in% names(jsons.dt)) {
        jsons.dt2 = copy(jsons.dt)
        jsons.dt2[, length_signatures := sapply(sigprofiler_sbs_count, function(x) length(unlist(x)))]
        jsons.dt2 = jsons.dt2[length_signatures != 0,]
        sigs.lst = mclapply(1:nrow(jsons.dt2), function(x) {
            jsons.sub.dt2 = jsons.dt2[x,]
            sigs.dt = jsons.sub.dt2$sigprofiler_sbs_count[[1]] %>% as.data.table()
            sigs.dt[, pair := jsons.sub.dt2$pair]
            sigs.dt[, tumor_type := jsons.sub.dt2$tumor_type]
            return(sigs.dt)
        }, mc.cores = cores)
        sigprofilerassignment_sbs_count.dt = rbindlist(sigs.lst, fill = TRUE)
    } else {
        sigprofilerassignment_sbs_count.dt = NULL
    }
    ## create list object to return
    list_return = list(deconstruct_sigs.dt, sigprofilerassignment_indels.dt, sigprofilerassignment_indels_counts.dt, sigprofilerassignment_sbs.dt, sigprofilerassignment_sbs_count.dt)
    names(list_return) = c("deconstruct_sigs.dt", "sigprofilerassignment_indels.dt", "sigprofilerassignment_indels_counts.dt", "sigprofilerassignment_sbs.dt", "sigprofilerassignment_sbs_counts.dt")
    return(list_return)
}


#' @name write_signature_jsons
#' @title write_signature_jsons
#' @description
#' writes the different distribution jsons for signatures from the list outputted by convert_signature_meta_json
#'
#' @param signatures_list list outputted from convert_sign
#' @param common_folder location of the signatures folder
#' @param cores cores for generating the signature distribution files
#' @return NULL
#' @export
#' @author Stanley Clarke

## write_signature_jsons(sigs.lst, signatures_folder)
## signatures_list = sigs.lst
## signatures_folder = paste0(common_folder,"signatures")
write_signature_jsons = function(signatures_list, common_folder, cores = 1) {
    names_list = names(signatures_list)
    ## deconstruct sigs dt- added to main SBS and SBS_deconstructsigs
    if("deconstruct_sigs.dt" %in% names(signatures_list)) {
        deconstruct_sigs.dt = signatures_list[["deconstruct_sigs.dt"]]
        signatures_add = names(deconstruct_sigs.dt) %>% grep("pair|tumor_type",.,invert = TRUE, value = TRUE)
        empty.lst = mclapply(signatures_add, function(sig) {
            cols_keep = c("pair","tumor_type",sig)
            sig.dt = deconstruct_sigs.dt[,..cols_keep] %>% setnames(.,c("pair","tumor_type","value"))
            sig.dt[,sig := sig]
            ## write_json(sig.dt,paste0(common_folder,"signatures/sbs/",sig,".json"),pretty = TRUE) ## deconstruct sigs as default for signatures at the moment
            ## write_json(sig.dt,paste0(common_folder,"signatures/sbs_deconstructsigs/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/deconstructsigs_sbs_fraction/",sig,".json"),pretty = TRUE)
            return(NULL)
        }, mc.cores = cores)
    }
    ## sigprofiler assignment indels-added to main insertionDeletion and insertionDeletion_sigprofilerassignment
    if("sigprofilerassignment_indels.dt" %in% names(signatures_list)) {
        sigprofilerassignment_indels.dt = signatures_list[["sigprofilerassignment_indels.dt"]]
        ## write indel signatures- sigprofilerassignment
        indels_add = names(sigprofilerassignment_indels.dt) %>% grep("pair|tumor_type",.,invert = TRUE, value = TRUE)
        empty.lst = mclapply(indels_add, function(sig) {
            cols_keep = c("pair","tumor_type",sig)
            sig.dt = sigprofilerassignment_indels.dt[,..cols_keep] %>% setnames(.,c("pair","tumor_type","value"))
            sig.dt[,sig := sig]
            write_json(sig.dt,paste0(common_folder,"signatures/insertionDeletion/",sig,".json"),pretty = TRUE) ##  sigprofiler default for ins/del at the moment
            ## write_json(sig.dt,paste0(common_folder,"signatures/insertionDeletion_sigprofilerassignment/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/sigprofiler_indel_fraction/",sig,".json"),pretty = TRUE)
            return(NULL)
        }, mc.cores = cores)
    }
    ## sigprofiler assignment indels counts-added to insertionDeletion_counts_sigprofilerassignment
    if("sigprofilerassignment_indels_counts.dt" %in% names(signatures_list)) {
        sigprofilerassignment_indels_counts.dt = signatures_list[["sigprofilerassignment_indels_counts.dt"]]
        ## write indel signatures- sigprofilerassignment
        indels_add = names(sigprofilerassignment_indels_counts.dt) %>% grep("pair|tumor_type",.,invert = TRUE, value = TRUE)
        empty.lst = mclapply(indels_add, function(sig) {
            cols_keep = c("pair","tumor_type",sig)
            sig.dt = sigprofilerassignment_indels_counts.dt[,..cols_keep] %>% setnames(.,c("pair","tumor_type","value"))
            sig.dt[,sig := sig]
            ## write_json(sig.dt,paste0(common_folder,"signatures/insertionDeletion_counts_sigprofilerassignment/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/sigprofiler_indel_count/",sig,".json"),pretty = TRUE)
            return(NULL)
        }, mc.cores = cores)
    }
    ## sigprofiler assignment sbs counts - added to sbs_counts_deconstructsigs
    if("sigprofilerassignment_sbs_counts.dt" %in% names(signatures_list)) {
        sigprofilerassignment_sbs_counts.dt = signatures_list[["sigprofilerassignment_sbs_counts.dt"]]
        ## write indel signatures- sigprofilerassignment
        sbs_add = names(sigprofilerassignment_sbs_counts.dt) %>% grep("pair|tumor_type",.,invert = TRUE, value = TRUE)
        empty.lst = mclapply(sbs_add, function(sig) {
            cols_keep = c("pair","tumor_type",sig)
            sig.dt = sigprofilerassignment_sbs_counts.dt[,..cols_keep] %>% setnames(.,c("pair","tumor_type","value"))
            sig.dt[,sig := sig]
            ## write_json(sig.dt,paste0(common_folder,"signatures/sbs_counts_deconstructsigs/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/sigprofiler_sbs_count/",sig,".json"),pretty = TRUE)
            return(NULL)
        }, mc.cores = cores)
    }
    ## sigprofiler assignment sbs counts - added to sbs_deconstructsigs
    if("sigprofilerassignment_sbs.dt" %in% names(signatures_list)) {
        sigprofilerassignment_sbs.dt = signatures_list[["sigprofilerassignment_sbs.dt"]]
        ## write indel signatures- sigprofilerassignment
        sbs_add = names(sigprofilerassignment_sbs.dt) %>% grep("pair|tumor_type",.,invert = TRUE, value = TRUE)
        empty.lst = mclapply(sbs_add, function(sig) {
            cols_keep = c("pair","tumor_type",sig)
            sig.dt = sigprofilerassignment_sbs.dt[,..cols_keep] %>% setnames(.,c("pair","tumor_type","value"))
            sig.dt[,sig := sig]
            ## write_json(sig.dt,paste0(common_folder,"signatures/sbs_deconstructsigs/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/sigprofiler_sbs_fraction/",sig,".json"),pretty = TRUE)
            write_json(sig.dt,paste0(common_folder,"signatures/sbs/",sig,".json"),pretty = TRUE) ## sigprofiler as default for signatures at the moment
            return(NULL)
        }, mc.cores = cores)
    }
}

